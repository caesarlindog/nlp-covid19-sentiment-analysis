{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('machinelearning': conda)",
   "metadata": {
    "interpreter": {
     "hash": "5694eae89c83a630f0be2b614947e66c2883c98761c83e3b5e0e997ba9dfa636"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "For this NLP project, the dataset is from here: https://www.kaggle.com/datatattle/covid-19-nlp-text-classification/notebooks\n",
    "\n",
    "It consists of tweets surrounding COVID-19. The data is already split into train and test sets with pre-labeled sentiments.\n",
    "\n",
    "I will be training using CountVectorizer for the sentiment analysis."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: en_core_web_sm==2.3.1 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.3.1/en_core_web_sm-2.3.1.tar.gz#egg=en_core_web_sm==2.3.1 in c:\\users\\c\\anaconda3\\envs\\machinelearning\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: spacy<2.4.0,>=2.3.0 in c:\\users\\c\\anaconda3\\envs\\machinelearning\\lib\\site-packages (from en_core_web_sm==2.3.1) (2.3.5)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\c\\anaconda3\\envs\\machinelearning\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.7.4)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\c\\anaconda3\\envs\\machinelearning\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.19.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\c\\anaconda3\\envs\\machinelearning\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (4.55.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\c\\anaconda3\\envs\\machinelearning\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.0.5)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\c\\anaconda3\\envs\\machinelearning\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\c\\anaconda3\\envs\\machinelearning\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.5)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in c:\\users\\c\\anaconda3\\envs\\machinelearning\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.5)\n",
      "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in c:\\users\\c\\anaconda3\\envs\\machinelearning\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (7.4.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\c\\anaconda3\\envs\\machinelearning\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (49.6.0.post20200925)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in c:\\users\\c\\anaconda3\\envs\\machinelearning\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.9.6)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in c:\\users\\c\\anaconda3\\envs\\machinelearning\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.0.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\c\\appdata\\roaming\\python\\python38\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.23.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in c:\\users\\c\\anaconda3\\envs\\machinelearning\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (0.8.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\c\\anaconda3\\envs\\machinelearning\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\c\\anaconda3\\envs\\machinelearning\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\c\\anaconda3\\envs\\machinelearning\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\c\\anaconda3\\envs\\machinelearning\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->en_core_web_sm==2.3.1) (2020.12.5)\n",
      "✔ Download and installation successful\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n",
      "✘ Couldn't link model to 'en'\n",
      "Creating a symlink in spacy/data failed. Make sure you have the required\n",
      "permissions and try re-running the command as admin, or use a virtualenv. You\n",
      "can still import the model as a module and call its load() method, or create the\n",
      "symlink manually.\n",
      "C:\\Users\\c\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\en_core_web_sm -->\n",
      "C:\\Users\\c\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\spacy\\data\\en\n",
      "⚠ Download successful but linking failed\n",
      "Creating a shortcut link for 'en' didn't work (maybe you don't have admin\n",
      "permissions?), but you can still load the model via its full package name: nlp =\n",
      "spacy.load('en_core_web_sm')\n",
      "You do not have sufficient privilege to perform this operation.\n",
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     C:\\Users\\c\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "import sklearn\n",
    "import warnings\n",
    "import markovify\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.pipeline import Pipeline\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "!python -m spacy download en\n",
    "nltk.download('gutenberg')"
   ]
  },
  {
   "source": [
    "## Importing Tweet Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"Corona_NLP_train.csv\", encoding=\"ISO-8859-1\")\n",
    "test = pd.read_csv(\"Corona_NLP_test.csv\", encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   UserName  ScreenName   Location     TweetAt  \\\n",
       "0      3799       48751     London  16-03-2020   \n",
       "1      3800       48752         UK  16-03-2020   \n",
       "2      3801       48753  Vagabonds  16-03-2020   \n",
       "3      3802       48754        NaN  16-03-2020   \n",
       "4      3803       48755        NaN  16-03-2020   \n",
       "\n",
       "                                       OriginalTweet           Sentiment  \n",
       "0  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...             Neutral  \n",
       "1  advice Talk to your neighbours family to excha...            Positive  \n",
       "2  Coronavirus Australia: Woolworths to give elde...            Positive  \n",
       "3  My food stock is not the only one which is emp...            Positive  \n",
       "4  Me, ready to go at supermarket during the #COV...  Extremely Negative  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>UserName</th>\n      <th>ScreenName</th>\n      <th>Location</th>\n      <th>TweetAt</th>\n      <th>OriginalTweet</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3799</td>\n      <td>48751</td>\n      <td>London</td>\n      <td>16-03-2020</td>\n      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n      <td>Neutral</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3800</td>\n      <td>48752</td>\n      <td>UK</td>\n      <td>16-03-2020</td>\n      <td>advice Talk to your neighbours family to excha...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3801</td>\n      <td>48753</td>\n      <td>Vagabonds</td>\n      <td>16-03-2020</td>\n      <td>Coronavirus Australia: Woolworths to give elde...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3802</td>\n      <td>48754</td>\n      <td>NaN</td>\n      <td>16-03-2020</td>\n      <td>My food stock is not the only one which is emp...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3803</td>\n      <td>48755</td>\n      <td>NaN</td>\n      <td>16-03-2020</td>\n      <td>Me, ready to go at supermarket during the #COV...</td>\n      <td>Extremely Negative</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "source": [
    "Only *OriginalTweet* will only be used to make the classifier."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(docs):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    preprocessed = []\n",
    "\n",
    "    for doc in docs:\n",
    "        tokenized = word_tokenize(doc)\n",
    "        cleaned = [stemmer.stem(lemmatizer.lemmatize(token.lower()))\n",
    "        for token in tokenized\n",
    "        if not token.lower() in stopwords.words(\"english\")\n",
    "        if token.isalpha()]\n",
    "\n",
    "        untokenized = \" \".join(cleaned)\n",
    "        preprocessed.append(untokenized)\n",
    "\n",
    "    return preprocessed"
   ]
  },
  {
   "source": [
    "## Using *preprocess*"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['menyrbi', 'chrisitv', 'http', 'http', 'http']\n",
      "['advic', 'talk', 'neighbour', 'famili', 'exchang', 'phone', 'number', 'creat', 'contact', 'list', 'phone', 'number', 'neighbour', 'school', 'employ', 'chemist', 'gp', 'set', 'onlin', 'shop', 'account', 'po', 'adequ', 'suppli', 'regular', 'med', 'order']\n",
      "['coronavirus', 'australia', 'woolworth', 'give', 'elder', 'disabl', 'dedic', 'shop', 'hour', 'amid', 'outbreak', 'http']\n",
      "['food', 'stock', 'one', 'empti', 'pleas', 'panic', 'enough', 'food', 'everyon', 'take', 'need', 'stay', 'calm', 'stay', 'safe', 'coronavirus', 'confin', 'confinementot', 'confinementgener', 'http']\n",
      "['readi', 'go', 'supermarket', 'outbreak', 'paranoid', 'food', 'stock', 'litterali', 'empti', 'coronavirus', 'serious', 'thing', 'pleas', 'panic', 'caus', 'shortag', 'coronavirusfr', 'restezchezv', 'stayathom', 'confin', 'http']\n",
      "['news', 'first', 'confirm', 'case', 'came', 'sullivan', 'counti', 'last', 'week', 'peopl', 'flock', 'area', 'store', 'purchas', 'clean', 'suppli', 'hand', 'sanit', 'food', 'toilet', 'paper', 'good', 'report', 'http']\n",
      "['cashier', 'groceri', 'store', 'share', 'insight', 'prove', 'credibl', 'comment', 'civic', 'class', 'know', 'talk', 'http']\n",
      "['supermarket', 'today', 'buy', 'toilet', 'paper', 'rebel', 'toiletpapercrisi', 'http']\n",
      "['due', 'retail', 'store', 'classroom', 'atlanta', 'open', 'busi', 'class', 'next', 'two', 'week', 'begin', 'monday', 'march', 'continu', 'process', 'onlin', 'phone', 'order', 'normal', 'thank', 'understand', 'http']\n",
      "['corona', 'prevent', 'stop', 'buy', 'thing', 'cash', 'use', 'onlin', 'payment', 'method', 'corona', 'spread', 'note', 'also', 'prefer', 'onlin', 'shop', 'home', 'time', 'fight', 'covid', 'govindia', 'indiafightscorona']\n",
      "['month', 'crowd', 'supermarket', 'restaur', 'howev', 'reduc', 'hour', 'close', 'mall', 'mean', 'everyon', 'use', 'entranc', 'depend', 'singl', 'supermarket', 'manila', 'lockdown', 'philippin', 'http']\n",
      "['due', 'situat', 'increas', 'demand', 'food', 'product', 'wait', 'time', 'may', 'longer', 'onlin', 'order', 'particular', 'beef', 'share', 'freezer', 'pack', 'thank', 'patienc', 'time']\n",
      "['horningsea', 'care', 'communiti', 'look', 'le', 'capabl', 'villag', 'ensur', 'stay', 'healthi', 'bring', 'shop', 'door', 'help', 'onlin', 'shop', 'self', 'isol', 'symptom', 'expos', 'somebodi', 'http']\n",
      "['need', 'stock', 'food', 'amazon', 'deliv', 'whatev', 'need', 'coronavirus', 'amazon', 'http']\n",
      "['adara', 'releas', 'resourc', 'center', 'travel', 'brand', 'insight', 'help', 'travel', 'brand', 'stay', 'consum', 'travel', 'behavior', 'trend', 'http', 'http']\n",
      "['line', 'groceri', 'store', 'unpredict', 'eat', 'safe', 'altern', 'find', 'whether', 'avoid', 'restaur', 'right', 'http', 'coronavirus', 'http']\n",
      "['http']\n",
      "['eyeonthearct', 'russia', 'consum', 'surveil', 'watchdog', 'report', 'case', 'high', 'arctic', 'man', 'travel', 'iran', 'observ', 'http', 'http']\n",
      "['amazon', 'glitch', 'stymi', 'whole', 'food', 'fresh', 'groceri', 'deliveri', 'spread', 'seen', 'signific', 'increas', 'peopl', 'shop', 'onlin', 'groceri', 'spokeswoman', 'said', 'statement', 'result', 'system', 'impact', 'affect', 'http']\n",
      "['struggl', 'pleas', 'consid', 'donat', 'food', 'bank', 'nonprofit', 'demand', 'servic', 'increas', 'impact', 'job', 'peopl', 'way', 'life']\n",
      "['nation', 'infict', 'covid', 'world', 'must', 'play', 'fair', 'china', 'gover', 'must', 'demand', 'china', 'adopt', 'new', 'guild', 'line', 'food', 'safti', 'chines', 'gover', 'guilti', 'irosponc', 'life', 'global', 'scale']\n",
      "['http', 'coronavirus', 'pandem', 'impact', 'consum', 'shop', 'behavior', 'purchas', 'decis', 'retail', 'sale', 'accord', 'first', 'insight', 'studi']\n",
      "['amaz', 'cheap', 'deal', 'go', 'help', 'trial', 'month', 'year', 'reson', 'price', 'subscript', 'dm', 'u', 'bestiptv', 'iptv', 'servic', 'iptv', 'iptvdeal', 'cheap', 'iptv', 'footbal', 'hd', 'movi', 'adult', 'cinema', 'hotmovi', 'iptvnew', 'adult']\n",
      "['amaz', 'cheap', 'deal', 'go', 'help', 'trial', 'month', 'year', 'reson', 'price', 'subscript', 'dm', 'u', 'bestiptv', 'iptv', 'servic', 'iptv', 'iptvdeal', 'cheap', 'iptv', 'footbal', 'hd', 'movi', 'adult', 'cinema', 'hotmovi', 'iptv', 'iptvlink']\n",
      "['grantshapp', 'done', 'ensur', 'food', 'essenti', 'product', 'supermarket', 'panic', 'buy', 'activ', 'discourag', 'left', 'checkout', 'staff', 'polic', 'action', 'selfish', 'profit']\n",
      "['uk', 'consum', 'poll', 'indic', 'major', 'expect', 'impact', 'last', 'month', 'march', 'expect', 'increas', 'next', 'tracker', 'see', 'full', 'result', 'retailx', 'coronavirus', 'consum', 'confid', 'tracker', 'http', 'http']\n",
      "['prepar', 'higher', 'demand', 'potenti', 'food', 'shortag', 'hunger', 'coalit', 'purchas', 'percent', 'food', 'implement', 'new', 'protocol', 'due', 'coronavirus', 'http']\n",
      "['morn', 'test', 'posit', 'covid', 'feel', 'ok', 'symptom', 'far', 'isol', 'sinc', 'found', 'possibl', 'exposur', 'virus', 'stay', 'home', 'peopl', 'pragmat', 'keep', 'updat', 'panic', 'http']\n",
      "['see', 'malici', 'price', 'increas', 'nyc', 'nyc', 'depart', 'consum', 'worker', 'protect', 'dcwp', 'set', 'page', 'digit', 'file', 'complaint', 'click', 'http', 'file', 'complaint', 'use', 'word', 'overcharg', 'http', 'covidnyc']\n",
      "['soon', 'dwindl', 'suppli', 'unlaw', 'panicki', 'peopl', 'break', 'close', 'store', 'amp', 'supermarket', 'raid', 'normal', 'crisi', 'massiv', 'coronavirus', 'stockup', 'amp', 'lockup']\n",
      "['countri', 'empti', 'shelf', 'peopl', 'see', 'buy', 'ensu', 'food', 'stock']\n",
      "['food', 'imag', 'nicest', 'groceri', 'store', 'one', 'richest', 'neighborhood', 'unit', 'state', 'http', 'breakingnew', 'break', 'coronavirus', 'coronavirusoutbreak', 'covid', 'collaps']\n",
      "['retail', 'store', 'closur', 'could', 'explod', 'coronavirus', 'via', 'cnbc', 'brickandmortar', 'http', 'http']\n",
      "['coronavirus', 'fun', 'fact', 'cough', 'groceri', 'store', 'get', 'whole', 'aisl', 'pretti', 'quick', 'coronavirusoutbreak', 'coronavirus']\n",
      "['sorri', 'say', 'finfabuk', 'event', 'cancel', 'due', 'health', 'wellb', 'attende', 'speaker', 'staff', 'top', 'prioriti', 'apolog', 'disappoint', 'may', 'caus', 'faq', 'answer', 'link', 'http']\n",
      "['went', 'supermarket', 'yesterday', 'toilet', 'paper', 'gone', 'anyth', 'corona', 'virus']\n",
      "['yes', 'buy', 'need', 'point', 'post', 'photo', 'peopl', 'supermarket', 'load', 'stuff', 'could', 'buy', 'elder', 'parent', 'kid', 'sibl', 'etc', 'ca', 'buy', 'everyth', 'need', 'viral', 'alr']\n",
      "['worri', 'impact', 'current', 'pandem', 'financ', 'publish', 'tip', 'help', 'manag', 'money', 'challeng', 'time', 'http', 'http']\n",
      "['wife', 'work', 'retail', 'amp', 'custom', 'came', 'yesterday', 'cough', 'everywher', 'say', 'request', 'deep', 'clean', 'store', 'compani', 'object', 'due', 'cost', 'recommend', 'team', 'spray', 'disinfect', 'amp', 'clean', 'gon', 'na', 'sick', 'due', 'capit']\n",
      "['go', 'supermarket', 'like', 'without', 'judg', 'coronavirusoutbreak', 'http']\n",
      "['provid', 'safe', 'shop', 'experi', 'custom', 'healthi', 'environ', 'associ', 'communiti', 'onlin', 'order', 'place', 'http', 'jlmco', 'jlmcobrand', 'coronapocolyps', 'coronavirus', 'coronavirusoutbreak', 'shoponlin', 'http']\n",
      "['curious', 'think', 'retail', 'shopper', 'lot', 'onlin', 'shop', 'bc', 'home', 'unabl', 'go', 'think', 'everyon', 'spook', 'get', 'extra', 'pair', 'shoe', 'economi', 'onlineshop', 'coronavirus', 'stayhom']\n",
      "['check', 'video', 'http', 'food', 'usa', 'market', 'due', 'coronavirus', 'panic', 'gon', 'na', 'die', 'starvat', 'coronavirusoutbreak', 'coronavirus', 'houston', 'nofood', 'notoiletpap', 'nohandshak', 'nohandsanit', 'pandem', 'totallockdown', 'walmart', 'http']\n",
      "['break', 'stori', 'onlin', 'cloth', 'shop', 'rise', 'peopl', 'find', 'mysteri', 'white', 'patch', 'form', 'cloth', 'quarantinelif', 'coronavirusoutbreak', 'coronavirus', 'imadethisup', 'fakenew', 'http']\n",
      "['line', 'outsid', 'target', 'custom', 'wait', 'store', 'open', 'morn']\n",
      "['south', 'african', 'stock', 'food', 'basic', 'good', 'coronavirus', 'panic', 'hit', 'http', 'coronavirussa', 'http']\n",
      "['pleas', 'share', 'know', 'someon', 'live', 'struggl', 'get', 'local', 'supermarket', 'due', 'issu', 'around', 'offer', 'free', 'deliveri', 'healthi', 'soup', 'nationwid', 'anyon', 'need', 'plus', 'freezabl']\n",
      "['peopl', 'post', 'share', 'photo', 'half', 'complet', 'empti', 'shelf', 'call', 'peopl', 'dumb', 'idiot', 'shop', 'groceri', 'store', 'lol', 'coronavirus']\n",
      "['never', 'thought', 'say', 'come', 'back', 'pleas', 'coronavirus', 'peoplearelosingtheirmind', 'stopthemad', 'stoppanicbuy']\n",
      "['restrict', 'spark', 'run', 'cannabi', 'store', 'close', 'yet', 'custom', 'stock', 'cannabi', 'weekend', 'prepar', 'could', 'retail', 'store', 'restrict', 'come', 'day', 'http']\n",
      "['everyth', 'see', 'current', 'outbreak', 'seen', 'previous', 'epidem', 'pandem', 'rise', 'fear', 'racism', 'panic', 'buy', 'food', 'medicin', 'conspiraci', 'theori', 'prolifer', 'quack', 'cure', 'http']\n",
      "['everyon', 'close', 'remain', 'open', 'emerg', 'store', 'thank', 'retail', 'worker', 'pandem', 'socialdistanc', 'retail', 'http']\n",
      "['stock', 'water', 'caus', 'util', 'compani', 'shut', 'middl', 'pandem', 'school', 'close', 'thier', 'door', 'lose', 'work', 'caus', 'kid', 'go', 'afford', 'month', 'worth', 'food', 'coronavirus', 'senatorromney', 'http']\n",
      "['dear', 'coronavirus', 'follow', 'social', 'distanc', 'rule', 'stay', 'home', 'prevent', 'spread', 'howev', 'spent', 'alarm', 'amount', 'money', 'shop', 'onlin', 'submit', 'expens', 'reimburs', 'let', 'know', 'coronapocolyps', 'coronavirus']\n",
      "['global', 'food', 'price', 'spread', 'covid', 'intensifi', 'across', 'sever', 'geographi', 'could', 'see', 'downward', 'pressur', 'come', 'month', 'due', 'continu', 'well', 'suppli', 'market', 'negat', 'impact', 'demand', 'result', 'virus']\n",
      "['morn', 'everyon', 'great', 'safe', 'day', 'coronavirus', 'stoppanicbuy', 'bekind', 'mufc']\n",
      "['thing', 'panic', 'buy', 'emerg', 'get', 'toilet', 'paper', 'import', 'afraid', 'worst', 'case', 'scenario', 'wash', 'tub', 'use', 'money', 'food', 'crazi', 'coronavirus']\n",
      "['thank', 'groceri', 'clerk', 'went', 'groceri', 'store', 'today', 'look', 'weari', 'eye', 'clerk', 'thank', 'realiz', 'thrust', 'front', 'line', 'panick', 'new', 'breed', 'first', 'respond', 'work', 'hard', 'serv', 'communiti', 'coronavirus']\n",
      "['outbreak', 'entir', 'world', 'retail', 'shop', 'malaysia', 'face', 'great', 'challeng', 'near', 'futur', 'onlin', 'shop', 'surpris', 'way', 'peopl', 'mani', 'lost', 'job', 'malaysia', 'covid']\n",
      "['thought', 'impact', 'coronavirus', 'food', 'market', 'http']\n",
      "['consum', 'corner', 'scammer', 'take', 'advantag', 'fear', 'coronavirus', 'cdc', 'flu', 'trend', 'alert', 'http', 'http']\n",
      "['mask', 'made', 'medic', 'personnel', 'consum', 'purchas', 'requir', 'materi', 'call', 'fabric', 'http']\n",
      "['work', 'capit', 'demand', 'packag', 'food', 'make', 'u', 'stay', 'open', 'oppos', 'close', 'health', 'safeti', 'lockdowncanada', 'coronavirus']\n",
      "['feel', 'like', 'ethic', 'still', 'stuff', 'like', 'order', 'deliveri', 'food', 'onlin', 'shop', 'etc', 'ship', 'isol', 'care', 'packag', 'love', 'one']\n",
      "['consum', 'told', 'pymnt', 'chang', 'daili', 'life', 'http', 'via', 'pymnt']\n",
      "['bought', 'hous', 'panic', 'think', 'buy', 'food', 'hous', 'tragic']\n",
      "['seen', 'facebook', 'group', 'busi', 'need', 'stop', 'increas', 'price', 'essenti', 'emerg', 'situat', 'frank', 'despic', 'total', 'void', 'communiti', 'spirit', 'nameandsham', 'covid', 'coronavirus', 'liverpool', 'http']\n",
      "['bobjlow', 'sad', 'misinform', 'think', 'give', 'diarrhoea', 'therefor', 'toilet', 'paper', 'atm', 'hygien', 'food', 'import']\n",
      "['yeah', 'parent', 'riski', 'peopl', 'covid', 'stay', 'home', 'go', 'supermarket', 'realli', 'stay', 'safe']\n",
      "['cn', 'coronavirus', 'group', 'mum', 'live', 'group', 'need', 'shield', 'week', 'month', 'mean', 'stay', 'hope', 'still', 'get', 'onlin', 'shop', 'need']\n",
      "['kind', 'like', 'say', 'word', 'make', 'sound', 'like', 'word', 'anymor', 'mani', 'peopl', 'think', 'news', 'b', 'make', 'go', 'store', 'panic', 'buy', 'food', 'basic', 'necess', 'noth', 'left']\n",
      "['hi', 'thank', 'make', 'onlin', 'shop']\n",
      "['corona', 'scare', 'send', 'price', 'skyrocket', 'mumbai', 'gt', 'gt', 'http', 'seafood', 'coronavirus', 'coronavirusoutbreak', 'coronavirusreachesdelhi', 'coronavirusupd', 'jhalakbollywood', 'jhalakkollywood', 'jhalaktollywood', 'http']\n",
      "['paus', 'student', 'loan', 'payment', 'addit', 'halt', 'interest', 'accumul', 'amp', 'stop', 'punit', 'student', 'loan', 'collect', 'would', 'provid', 'much', 'need', 'immedi', 'relief', 'individu', 'unabl', 'work', 'amp', 'face', 'econom', 'hardship']\n",
      "['balaji', 'consum', 'side', 'tech', 'chines', 'group', 'alreadi', 'demostr', 'elisa', 'test', 'strip', 'though', 'detail', 'lack', 'consum', 'though', 'would', 'deem', 'waiv', 'test', 'come', 'easili']\n",
      "['lost', 'wage', 'either', 'due', 'ill', 'virus', 'econom', 'impact', 'mean', 'increas', 'demand', 'urg', 'support', 'bill', 'includ', 'support', 'food', 'bank', 'flexibl', 'school', 'meal', 'increas']\n",
      "['action', 'selfish', 'ceo', 'groceri', 'store', 'would', 'time', 'peopl', 'shop', 'show', 'id', 'saw', 'young', 'coupl', 'roll', 'tp', 'one', 'full', 'crap', 'well', 'mayb', 'coronavirusoutbreak', 'http']\n",
      "['coronavirus', 'pose', 'complex', 'puzzl', 'compani', 'deliveri', 'capac', 'may', 'buckl', 'surg', 'demand', 'http', 'via', 'wsj', 'servic', 'food', 'deliveri', 'coronavirus']\n",
      "['thejoshuaturn', 'afneil', 'borisjohnson', 'disgust', 'disgrac', 'charg', 'inflat', 'price', 'item', 'stop', 'spread', 'govern', 'realli', 'need', 'someth', 'abou']\n",
      "['retail', 'close', 'physic', 'store', 'curtail', 'hour', 'result', 'ago', 'put', 'addit', 'pressur', 'omnichannel', 'altern', 'like', 'groceri', 'deliveri', 'curbsid', 'pick', 'http', 'ecommerc', 'omnichannel', 'retail', 'digit']\n",
      "['check', 'folk', 'cal', 'like', 'idea', 'la', 'habra', 'supermarket', 'offer', 'special', 'hour', 'senior', 'amid', 'crisi', 'http']\n",
      "['love', 'hate', 'head', 'advic', 'amp', 'borisjohnson', 'blip', 'life', 'happen', 'whing', 'dont', 'panic', 'buy', 'food', 'wont', 'run', 'spend', 'time', 'famili', 'use', 'common', 'sens', 'coronavirus']\n",
      "['open', 'letter', 'hold', 'organ', 'other', 'precipic', 'crisi', 'household', 'economi', 'pleas', 'suspend', 'debt', 'sixti', 'day', 'respons', 'crisi', 'feel', 'free', 'sign', 'http', 'http']\n",
      "['covid', 'coronavirus', 'want', 'spread', 'news', 'older', 'australian', 'particular', 'still', 'mobil', 'without', 'famili', 'support', 'http']\n",
      "['sad', 'surpris', 'heard', 'one', 'payer', 'exec', 'lay', 'low', 'hope', 'blow', 'mind', 'boggl', 'stupid', 'nonprofit', 'blue', 'plan', 'http']\n",
      "['work', 'retail', 'keep', 'stock', 'back', 'older', 'custom', 'frank', 'come', 'store', 'bread', 'see', 'empti', 'shelv', 'say', 'worri', 'pal', 'save', 'pat', 'n', 'bean', 'could', 'get', 'disciplin', 'yes', 'care', 'got', 'coronavirus']\n",
      "['attempt', 'lengthen', 'runway', 'market', 'budget', 'slash', 'hire', 'frozen', 'staf', 'matrix', 'redrawn', 'dive', 'deep', 'consum', 'startup', 'battl', 'impact', 'busi']\n",
      "['time', 'distilleri', 'remain', 'oper', 'offer', 'public', 'tour', 'host', 'function', 'event', 'retail', 'store', 'also', 'close', 'http']\n",
      "['pleas', 'hoard', 'food', 'water', 'absolut', 'need', 'panic', 'buy', 'suppli', 'chain', 'complet', 'interrupt', 'pleas', 'hoard', 'sanit', 'product', 'peopl', 'realli', 'need', 'probabl', 'dontpanicbuy', 'coronavirus']\n",
      "['fact', 'can', 'food', 'toxic', 'chemic', 'store', 'bought', 'hand', 'sanit', 'stock', 'yet', 'fresh', 'fruit', 'veget', 'herb', 'fulli', 'stock', 'show', 'human', 'idea', 'immun', 'system', 'work', 'quarantinelif']\n",
      "['call', 'mum', 'dad', 'uk', 'great', 'offer', 'help', 'onlin', 'shop', 'etc', 'might', 'sometim', 'forget', 'alway', 'easi', 'far', 'parent', 'like', 'tech', 'realli', 'use', 'covid', 'coronavirus']\n",
      "['peopl', 'seen', 'stock', 'good', 'trolley', 'panic', 'buy', 'rumour', 'spread', 'today', 'hypermarket', 'kajang', 'march', 'pictur', 'shafwan', 'zaidon']\n",
      "['often', 'see', 'major', 'news', 'event', 'crimin', 'tri', 'take', 'advantag', 'situat', 'coronavirus', 'except', 'guidanc', 'attorney', 'general', 'offic', 'http']\n",
      "['pretti', 'sure', 'within', 'week', 'two', 'supermarket', 'suppli', 'chain', 'dri', 'counti', 'effect', 'possibl', 'go', 'lockdown', 'would', 'govern', 'introduc', 'form', 'ration', 'peopl', 'eat', 'somehow', 'think']\n",
      "['supermarket', 'worker', 'frontlin', 'extraordinari', 'time', 'retail', 'extrem', 'pressur', 'shop', 'pleas', 'remain', 'calm', 'thank', 'worker', 'everyth', 'keep', 'shelf', 'stock', 'checkout', 'move', 'http']\n",
      "['worri', 'worri', 'peopl', 'panick', 'plan', 'gt', 'panic', 'buy', 'food', 'gt', 'focus', 'import', 'issu', 'gt', 'best', 'opportun', 'posit', 'outcom', 'creat', 'structur', 'reduc', 'key', 'decis', 'flourish', 'stay', 'safe']\n",
      "['kroger', 'biggest', 'supermarket', 'chain', 'unit', 'state', 'employe', 'mani', 'receiv', 'sick', 'leav', 'even', 'employe', 'test', 'posit', 'kroger', 'still', 'wo', 'provid', 'paid', 'sick', 'leav', 'everyon', 'http']\n",
      "['kroger', 'instead', 'paid', 'sick', 'leav', 'kroger', 'provid', 'week', 'paid', 'leav', 'peopl', 'test', 'posit', 'place', 'mandatori', 'quarantin', 'insuffici', 'protect', 'staff', 'public', 'especi', 'littl', 'test', 'av']\n",
      "['follow', 'went', 'shop', 'day', 'ago', 'pain', 'necessari', 'protect', 'groceri', 'shop', 'consum', 'report', 'stayhealthi', 'http']\n",
      "['joncoopertweet', 'took', 'pictur', 'today', 'home', 'groceri', 'store', 'montgomeri', 'counti', 'md', 'flour', 'sugar', 'sweet', 'potato', 'potato', 'orang', 'juic', 'paper', 'towel', 'toilet', 'paper', 'low', 'meat', 'mac', 'amp', 'chees', 'coronapocolyps', 'panicbuy']\n",
      "['hate', 'groceri', 'shop', 'general', 'swear', 'onlin', 'next', 'shop', 'deal', 'swath', 'panic', 'buyer', 'covid', 'coronavirus', 'coronavirusuk', 'anxieti', 'panicbuyinguk', 'moron']\n",
      "['rapid', 'deliveri', 'food', 'order', 'made', 'sinc', 'slot', 'elsewher', 'week', 'seem', 'fine', 'email', 'list', 'stock', 'deliv', 'one', 'bottl', 'orang', 'juic', 'coronavirus', 'panicbuy', 'whatashitshow']\n",
      "['thank', 'groceri', 'store', 'employe', 'work', 'hard', 'make', 'sure', 'everyon', 'get', 'need', 'pleas', 'kind', 'fault', 'short', 'suppli', 'corona', 'â', 'http']\n",
      "['also', 'need', 'said', 'go', 'groceri', 'store', 'done', 'complet', 'safe', 'mean', 'without', 'risk', 'get', 'coronavirus', 'spread', 'reduc', 'risk', 'stay', 'ft', 'peopl', 'amp', 'wash', 'hand', 'ca', 'elimin']\n",
      "['mayb', 'come', 'recess', 'might', 'play', 'three', 'phase', 'damag', 'main', 'street', 'ongo', 'cb', 'rescu', 'temp', 'recoveri', 'credit', 'mkt', 'recoveri', 'consum', 'econ', 'unknown', 'second', 'shock', 'later', 'final', 'bring', 'wall', 'street', 'altogeth', 'spx', 'rut', 'ndx']\n",
      "['know', 'end', 'world', 'bootsuk', 'surgic', 'spirit', 'stock', 'onlin', 'wo', 'receiv', 'stock', 'suppos', 'disinfect', 'hand', 'coronavirus', 'coronapocolyps', 'panic', 'shop', 'http']\n",
      "['get', 'real', 'world', 'know', 'real', 'mani', 'world', 'pleas', 'sign', 'petit', 'food', 'bev', 'peopl', 'colorado', 'http']\n",
      "['amid', 'distanc', 'crisi', 'starbuck', 'move', 'http']\n",
      "['abilen', 'bar', 'feel', 'econom', 'impact', 'http']\n",
      "['updat', 'make', 'sure', 'check', 'local', 'list', 'see', 'time', 'drive', 'starbuck', 'use', 'model', 'earli', 'close', 'includ', 'king', 'sooper', 'sam', 'club', 'http']\n",
      "['supermarket', 'la', 'habra', 'tri', 'help', 'local', 'senior', 'pandem', 'open', 'door', 'earli', 'day', 'exclus', 'shopper', 'older', 'http']\n",
      "['supermarket', 'la', 'habra', 'tri', 'help', 'local', 'senior', 'pandem', 'open', 'door', 'earli', 'day', 'exclus', 'shopper', 'http']\n",
      "['someth', 'elder', 'peopl', 'stock', 'ton', 'food', 'essenti', 'buy', 'need', 'first', 'greedi', 'panick', 'buyer', 'get', 'need', 'stoppanickbuy', 'thinkingofoth', 'coronavirus']\n",
      "['kid', 'get', 'mild', 'symptom', 'chanc', 'transmiss', 'high', 'studi', 'http']\n",
      "['new', 'cspi', 'guid', 'examin', 'largest', 'restaur', 'chain', 'sale', 'handl', 'paid', 'sick', 'leav', 'pandem', 'result', 'good', 'disclos', 'paid', 'leav', 'polici', 'chain', 'offer', 'sick', 'leav', 'locat', 'nationwid', 'http']\n",
      "['sparintheuk', 'confirm', 'store', 'signag', 'say', 'take', 'extra', 'precaut', 'light', 'staff', 'state', 'noth', 'chang', 'effort', 'manag', 'protect', 'retail', 'worker', 'speed', 'crucial']\n",
      "['idiot', 'work', 'caus', 'unnecessari', 'problem', 'empti', 'shelf', 'supermarket', 'got', 'enough', 'rice', 'last', 'year', 'panicshop', 'pricegoug', 'idiot', 'http']\n",
      "['fring', 'idiot', 'like', 'caus', 'price', 'rise', 'amp', 'creat', 'shortag', 'also', 'probabl', 'wast', 'lot', 'money', 'expiri', 'date', 'shopkeep', 'must', 'use', 'ration', 'fair', 'custom', 'pricegoug', 'hoarder', 'idiot', 'panicbuy', 'selfishpeopl', 'http']\n",
      "['congress', 'temporarili', 'paralyz', 'hous', 'still', 'final', 'technic', 'correct', 'coronavirus', 'bill', 'replouiegohmert', 'current', 'hold', 'anyway', 'insist', 'bill', 'read', 'floor', 'would', 'requir', 'hous', 'return', 'senat', 'fight', 'issu']\n",
      "['consum', 'financi', 'protect', 'bureau', 'report', 'one', 'employe', 'test', 'posit', 'feder', 'financi', 'regul', 'mandat', 'employe', 'work', 'home', 'http']\n",
      "['aircanada', 'poor', 'custom', 'servic', 'let', 'algorithm', 'run', 'price', 'state', 'emerg', 'refund', 'cost', 'also', 'poor', 'staf']\n",
      "['love', 'groceri', 'store', 'set', 'hour', 'prefer', 'morn', 'elder', 'popul', 'compromis', 'immun', 'system', 'use', 'store', 'good', 'clear', 'think', 'brianschatz', 'maziehirono', 'nygovcuomo', 'govinsle', 'covid', 'coronavirus', 'http']\n",
      "['temporarili', 'lost', 'job', 'check', 'amazon', 'hire', 'handl', 'surg', 'coronavirus', 'relat', 'buy', 'http']\n",
      "['cgafun', 'danielandrewsmp', 'daughter', 'stori', 'like', 'friend', 'supermarket', 'job', 'one', 'said', 'adult', 'act', 'like', 'fault', 'stand', 'woman', 'refus', 'put', 'back', 'box']\n",
      "['current', 'self', 'isol', 'symptomat', 'think', 'support', 'elder', 'friend', 'done', 'onlin', 'shop', 'agre', 'phone', 'call', 'daili', 'might', 'even', 'attempt', 'skype', 'video', 'call', 'unitedagainstdementia', 'coronavirus', 'alzheimerssoc']\n",
      "['peopl', 'walk', 'retail', 'store', 'problem', 'respons', 'make', 'shit', 'spread', 'feel', 'guilti', 'stop', 'shop', 'onlin', 'shop', 'avail', 'home', 'coronavirus', 'retail']\n",
      "['ny', 'awar', 'uptick', 'coronavirus', 'scam', 'social', 'medium', 'email', 'text', 'websit', 'awar', 'scam', 'involv', 'financi', 'product', 'servic', 'visit', 'nydf', 'websit', 'call', 'consum', 'hotlin', 'http']\n",
      "['unpopularopinion', 'abl', 'tell', 'much', 'communiti', 'understand', 'restrict', 'movement', 'order', 'empti', 'supermarket', 'shelf']\n",
      "['kati', 'move', 'weekend', 'amongst', 'covid', 'panic', 'yes', 'food', 'toilet', 'paper', 'self', 'respect', 'also', 'least']\n",
      "['need', 'help', 'senior', 'coronavirusoutbreak', 'http']\n",
      "['fyi', 'call', 'chines', 'virus', 'notic', 'nasti', 'mention', 'support', 'industri', 'help', 'stock', 'market', 'trump', 'still', 'tri', 'cut', 'medicar', 'amp', 'social', 'secur', 'benefit', 'food', 'stamp', 'remov', 'pre', 'exist', 'condit', 'coverag', 'aca']\n",
      "['store', 'charlott', 'continu', 'voluntarili', 'shut', 'door', 'due', 'coronavirus', 'concern', 'tough', 'decis', 'one', 'mani', 'store', 'deem', 'necessari', 'rememb', 'possibl', 'onlin', 'shop', 'option', 'still', 'want', 'support', 'busi', 'specnewsclt', 'http']\n",
      "['heb', 'like', 'shop', 'fan', 'appreci', 'effort', 'limit', 'food', 'shortag', 'amp', 'spread', 'tho', 'concern', 'lack', 'push', 'toward', 'curbsid', 'pickup', 'amp', 'deliveri', 'addit', 'charg', 'per', 'item', 'cart']\n",
      "['happi', 'n', 'friend', 'know', 'everyon', 'uneasi', 'that', 'go', 'coronavirus', 'let', 'forget', 'small', 'busi', 'need', 'support', 'whether', 'shop', 'onlin', 'orderingâ', 'http']\n",
      "['good', 'move', 'tackl', 'spread', 'pleas', 'implement', 'new', 'polici', 'restrict', 'consum', 'hoard', 'good', 'store', 'point', 'creat', 'safeti', 'measur', 'peopl', 'chang', 'selfish']\n",
      "['offic', 'readi', 'prosecut', 'deal', 'coronavirus', 'texan', 'need', 'file', 'pricegoug', 'complaint', 'call', 'onlin', 'http']\n",
      "['consum', 'protect', 'alert', 'awar', 'coronavirus', 'relat', 'cyber', 'secur', 'scam', 'reveal', 'person', 'financi', 'info', 'email', 'avoid', 'click', 'unsolicit', 'link', 'use', 'trust', 'sourc', 'alway', 'report', 'attack', 'need', 'file', 'complaint', 'http']\n",
      "['kenyantraff', 'queue', 'buy', 'gun', 'la', 'buyer', 'tell', 'scare', 'happen', 'peopl', 'run', 'food', 'suppli', 'need', 'protect', 'famili', 'live', 'thetodayshow', 'coronavirus', 'panic', 'hit', 'la', 'http', 'via']\n",
      "['spark', 'manila', 'call', 'centr', 'close', 'help', 'prevent', 'spread', 'covid', 'call', 'rout', 'nz', 'base', 'help', 'desker', 'instead', 'spark', 'ask', 'patienc', 'call', 'peopl', 'use', 'myspark', 'app', 'visit', 'retail', 'store']\n",
      "['feel', 'like', 'lotteri', 'much', 'worth', 'stockmarket', 'toiletpap', 'arizona', 'coronavirus', 'stoppanicbuy', 'foxnew', 'http']\n",
      "['bad', 'habit', 'definit', 'guilti', 'staff', 'definit', 'need', 'avoid', 'wear', 'scrub', 'public', 'especi', 'nobodi', 'want', 'see', 'groceri', 'store', 'medtwitt', 'coronavirus']\n",
      "['world', 'leader', 'still', 'realiz', 'kashmir', 'struggl', 'western', 'state', 'panic', 'stock', 'pile', 'water', 'food', 'suppli', 'imagin', 'lockdown', 'month', 'wake', 'coronavirusoutbreak', 'kashmirlockdown', 'kashmiri', 'coronapocolyps']\n",
      "['abl', 'get', 'doggo', 'food', 'due', 'panic', 'buy', 'due', 'european', 'suppli', 'issu', 'caus', 'order', 'amazon', 'paid', 'wonder', 'get', 'doggo', 'ration']\n",
      "['onlin', 'shop', 'past', 'day', 'coronavirus']\n",
      "['govern', 'say', 'start', 'social', 'distanc', 'work', 'retail', 'ca', 'talk', 'custom', 'store', 'lol', 'fml', 'go', 'catch']\n",
      "['plus', 'side', 'save', 'money', 'onlin', 'shop', 'packag', 'china', 'hella', 'delay', 'car', 'wan', 'na', 'use', 'public', 'transport', 'hell', 'wan', 'na', 'around', 'peopl', 'appar', 'work', 'wash', 'hand', 'wipe', 'as']\n",
      "['hear', 'nation', 'quarantin', 'go', 'start', 'wednesday', 'said', 'stock', 'essenti', 'food', 'ammo', 'believ', 'go', 'get', 'ugli', 'coronavirus', 'nationalquarantin']\n",
      "['food', 'bank', 'close', 'ca', 'sourc', 'enough', 'item', 'thank', 'fckwit', 'everyth', 'care', 'broke', 'three', 'kid', 'ca', 'feed', 'long', 'mths', 'pasta', 'stockpil', 'let', 'starv', 'coronavirus']\n",
      "['dear', 'hoarder', 'covid', 'coronapocolyps', 'coronavirus', 'covid', 'hoarder', 'groceri', 'panicshop', 'stoppanicbuy', 'http']\n",
      "['first', 'shop', 'make', 'effort', 'could', 'realli', 'win', 'pr', 'game', 'make', 'real', 'differ', 'http']\n",
      "['come', 'trumpisanidiot', 'trumpneedstoshutup', 'trend', 'real', 'peopl', 'freak', 'store', 'keep', 'food', 'shelf', 'stock', 'market', 'control', 'realdonaldtrump', 'pleas', 'sake', 'counti', 'shut', 'coronavirus']\n",
      "['mum', 'actual', 'mount', 'dispens', 'soap', 'wash', 'hand', 'enter', 'supermarket', 'chanc']\n",
      "['would', 'list', 'plethora', 'unfortun', 'day', 'job', 'health', 'care', 'supermarket', 'retail', 'everyon', 'buck', 'take', 'care', 'sick', 'feed', 'hungri', 'coronavirus', 'staysaf', 'frontlin']\n",
      "['thing', 'may', 'stockup', 'thing', 'get', 'crazi', 'chocol', 'make', 'remov', 'conceal', 'dark', 'circl', 'chew', 'gum', 'pringl', 'seed', 'grow', 'flower', 'manual', 'surviv', 'apocalyps', 'chocol', 'gin', 'kitten', 'heel', 'shoe', 'coronavirus']\n",
      "['pleas', 'read', 'full', 'lava', 'statement', 'amp', 'announc', 'onlin', 'store', 'consum', 'electron', 'comput', 'interfac', 'http', 'http']\n",
      "['cleanshelf', 'supermarket', 'sanit']\n",
      "['walmart', 'target', 'kroger', 'increas', 'worker', 'onlin', 'shop', 'add', 'time', 'slot', 'pick', 'deliveri', 'hire', 'worker', 'short', 'time', 'busi', 'shut', 'winwin', 'coronavirus', 'stayindoorsandshop']\n",
      "['thank', 'northgateglzmrk', 'take', 'care', 'http']\n",
      "['also', 'peopl', 'stock', 'soap', 'hand', 'sanitis', 'toilet', 'roll', 'leav', 'shelf', 'empti', 'rest', 'u', 'realis', 'stop', 'spread', 'coronavirus', 'peopl', 'need', 'abl', 'wash', 'hand', 'stoppanicbuy', 'http']\n",
      "['near', 'year', 'old', 'nana', 'stock', 'pile', 'food', 'toilet', 'roll', 'stock', 'cupboard', 'two', 'full', 'tub', 'horlick', 'prioriti', 'coronavirus', 'http']\n",
      "['person', 'capabl', 'onlin', 'shop', 'would', 'encourag', 'relat', 'friend', 'acquaint', 'shop', 'citi', 'state', 'countri', 'altern', 'pick', 'person', 'coronavirus', 'coronavirusoutbreak']\n",
      "['televangelist', 'make', 'kill', 'covid', 'panic', 'sell', 'meal', 'day', 'worth', 'food', 'almost', 'sure', 'least', 'cheaper', 'two', 'month', 'ago']\n",
      "['retail', 'edit', 'fit', 'room', 'close', 'store', 'pact', 'peopl', 'upset', 'tri', 'cloth', 'worst', 'thing', 'mind', 'rn', 'abl', 'fit', 'pair', 'jean', 'restaur', 'bar', 'close', 'remind', 'ignor', 'corpor', 'america']\n",
      "['opportun', 'amp', 'challeng', 'caus', 'reverselogist', 'even', 'appar', 'current', 'pandem', 'mani', 'store', 'close', 'physic', 'locat', 'even', 'consum', 'turn', 'onlin', 'shop', 'http', 'ecommerc', 'return', 'coronavirus', 'http']\n",
      "['photo', 'edinburgh', 'supermarket', 'last', 'night', 'happen', 'work', 'one', 'worker', 'uk', 'gov', 'class', 'coupl', 'week', 'ago', 'hit', 'u', 'bad', 'thread', 'http']\n",
      "['bbchealth', 'someon', 'group', 'distanc', 'enough', 'driver', 'deliv', 'onlin', 'shop', 'amp', 'friend', 'relat', 'posit', 'amp', 'group']\n",
      "['actual', 'footag', 'tri', 'go', 'groceri', 'store', 'weekend', 'sure', 'toilet', 'paper', 'pleas', 'rememb', 'togeth', 'panicbuy', 'coronavirus', 'http']\n",
      "['seen', 'b', 'pop', 'facebook', 'various', 'communiti', 'group', 'call', 'toll', 'free', 'number', 'infant', 'formula', 'tell', 'find', 'formula', 'retail', 'store', 'due', 'send', 'full', 'case', 'free', 'formula', 'hoax', 'http']\n",
      "['fyi', 'check', 'freez', 'dri', 'food', 'compani', 'seem', 'everyon', 'sold', 'stock', 'backlog', 'week', 'coronavirus']\n",
      "['although', 'panic', 'stockpil', 'may', 'left', 'shelf', 'empti', 'may', 'silver', 'line', 'coronavirus', 'cloud', 'rise', 'onlin', 'groceri', 'shop', 'deliveri', 'servic', 'like', 'thespoontech', 'http']\n",
      "['panick', 'bought', 'amp', 'enough', 'provis', 'amp', 'famili', 'day', 'also', 'car', 'thank', 'idiot', 'smash', 'mine', 'last', 'week', 'onlin', 'shop', 'slot', 'week', 'wo', 'kill', 'famili', 'lack', 'food']\n",
      "['mass', 'hysteria', 'go', 'success', 'deal', 'major', 'contract', 'see', 'mild', 'flu', 'symptom', 'need', 'panic', 'buy', 'month', 'worth', 'toilet', 'paper', 'can', 'food']\n",
      "['went', 'store', 'today', 'can', 'food', 'gone', 'need', 'toilet', 'paper', 'actual', 'got', 'pack', 'roll', 'got', 'milk', 'cat', 'treat', 'well', 'thank', 'god', 'save', 'food', 'still', 'stuff', 'case', 'provinc', 'panic', 'buy', 'common']\n",
      "['http', 'call', 'small', 'busi', 'chicago', 'depart', 'busi', 'affair', 'amp', 'consum', 'protect', 'bacp', 'solicit', 'feedback', 'develop', 'resourc', 'measur', 'support', 'small', 'busi', 'impact', 'pleas', 'fill', 'survey', 'asap']\n",
      "['work', 'supermarket', 'store', 'live', 'paycheck', 'paycheck']\n",
      "['consum', 'told', 'pymnt', 'chang', 'daili', 'life', 'http']\n",
      "['plan', 'suppli', 'food', 'borisjohnson', 'panic', 'buy', 'crazi', 'supermarket', 'slot', 'deliveri', 'ration', 'seem', 'sensibl', 'ca', 'suggest', 'feebl', 'month', 'without', 'tell', 'u', 'eat', 'coronavirus']\n",
      "['hold', 'organ', 'debt', 'relief', 'american', 'household', 'impact', 'respons', 'sign', 'petit', 'http', 'via', 'chang']\n",
      "['taken', 'henk', 'zwoferink', 'saturday', 'black', 'beauti', 'haul', 'train', 'bring', 'last', 'tourist', 'home', 'colleagu', 'workinghard', 'keep', 'suppli', 'chain', 'run', 'respect', 'measur', 'ensur', 'everyon', 'safeti', 'pleasur', 'work', 'dedicatedpeopl', 'http']\n",
      "['safe', 'work', 'amid', 'coronavirus', 'http', 'via', 'phillyinquir']\n",
      "['american', 'stock', 'food', 'concern', 'rise', 'thing', 'bought', 'list', 'extra', 'box', 'pasta', 'http']\n",
      "['nordstrom', 'rack', 'store', 'make', 'effort', 'washington', 'st', 'market', 'drive', 'store', 'sale', 'weekend', 'jwn', 'retail', 'coronavirus', 'retailnew', 'http']\n",
      "['avoid', 'coronavirus', 'phish', 'scam', 'consum', 'report', 'http', 'coronavirus', 'coronavirus', 'coronavirusupd', 'coronapocolyps']\n",
      "['updat', 'groceri', 'store', 'shop', 'experi', 'weekend', 'today', 'u', 'know', 'store', 'still', 'stock', 'coronavirus', 'lotl']\n",
      "['colleagu', 'text', 'ask', 'need', 'anyth', 'supermarket', 'could', 'buy', 'carton', 'unsweeten', 'almond', 'milk', 'tri', 'convinc', 'millenni', 'materi', 'say', 'like']\n",
      "['stock', 'market', 'correct', 'currenc', 'rate', 'correct', 'oil', 'price', 'correct', 'interest', 'rate', 'chang', 'currenc', 'rate', 'fluctuat', 'coronavirus', 'coronavirusindia', 'lifestyl', 'correct', 'wisdom', 'collect', 'respect', 'natur', 'reciproc', 'one']\n",
      "['nashterr', 'mccroriejim', 'rogerscarmen', 'ddcampassr', 'weseeyouweknow', 'randallkraft', 'datofreddi', 'spa']\n",
      "['casper', 'provid', 'busi', 'updat', 'http', 'york', 'busi', 'wire', 'casper', 'sleep', 'nyse', 'cspr', 'today', 'provid', 'updat', 'north', 'america', 'retail', 'store', 'oper', 'respons', 'continu', 'spread', 'l', 'http']\n",
      "['left', 'supermarket', 'right', 'supermarket', 'take', 'guess', 'countri', 'press', 'call', 'hyster', 'dysfunct']\n",
      "['panic', 'buy', 'thank', 'medium', 'think', 'elder', 'disabl', 'get', 'buy', 'food', 'essenti', 'covid', 'coronavirus', 'panicshop', 'http']\n",
      "['alreadi', 'stock', 'food', 'ammo', 'next', 'step', 'sorri', 'america', 'ca', 'shoot', 'way', 'coronavirus', 'http']\n",
      "['make', 'groceri', 'store', 'pickup', 'next', 'week', 'would', 'reduc', 'crowd', 'panic', 'buy', 'contamin', 'strain', 'worker', 'googl', 'could', 'help', 'build', 'app', 'day', 'open', 'store', 'hr', 'senior', 'might', 'le', 'tech', 'savvi', 'coronavirus']\n",
      "['join', 'hand', 'uae', 'effort', 'contain', 'spread', 'coronavirus', 'consid', 'mall', 'visitor', 'communiti', 'gym', 'play', 'area', 'amp', 'amus', 'centr', 'stay', 'close', 'lulu', 'hypermarket', 'store', 'oper', 'routin', 'http']\n",
      "['given', 'restrict', 'around', 'covid', 'fic', 'postpon', 'til', 'nov', 'interest', 'food', 'secur', 'increas', 'amp', 'meet', 'demand', 'thought', 'provok', 'discuss', 'examin', 'food', 'issu', 'experienc', 'epidem', 'amp', 'like', 'experi', 'go', 'forward']\n",
      "['peopl', 'take', 'serious', 'get', 'stuck', 'indoor', 'food', 'decid', 'necessari', 'stock', 'gt', 'gt', 'gt', 'gt']\n",
      "['sarahhollenbeck', 'myclearwat', 'abcactionnew', 'kept', 'hear', 'boomer', 'gon', 'na', 'travel', 'cheap', 'flight', 'infect', 'meanwhil', 'major', 'boomer', 'hunker', 'home', 'afraid', 'go', 'groceri', 'store', 'socialdista']\n",
      "['gt', 'massgovernor', 'announc', 'loan', 'fund', 'administ', 'massgcc', 'provid', 'financi', 'relief', 'busi', 'includ', 'nonprofit', 'lt', 'amp', 'employe', 'impact', 'mabiz', 'releas', 'http', 'appli', 'http', 'http']\n",
      "['pasta', 'pasta', 'sauc', 'pizza', 'sold', 'groceri', 'store', 'everyon', 'dalla', 'becom', 'italian', 'grandma', 'dalla', 'coronapocolyps']\n",
      "['panic', 'fear', 'fear', 'mind', 'killer', 'pres', 'work', 'privat', 'sector', 'ensur', 'everyon', 'access', 'food', 'amp', 'suppli', 'turn', 'cnn', 'resist', 'herd', 'mental', 'coronaviruspandem', 'coronavirus', 'coronapocolyps', 'hea', 'th', 'http']\n",
      "['retail', 'store', 'close', 'end', 'march', 'keep', 'staff', 'custom', 'safe', 'crisi', 'continu', 'fulfil', 'ship', 'order', 'place', 'onlin', 'pickup', 'avail', 'return', 'regular', 'hour', 'http']\n",
      "['drsanjaygupta', 'johnberman', 'newday', 'major', 'busi', 'trump', 'tout', 'say', 'suppli', 'realli', 'onlin', 'critic', 'suppli', 'avail', 'onlin', 'shop', 'best', 'socialdistanc', 'need', 'help', 'arena', 'suppli', 'via', 'onlin', 'coronavir']\n",
      "['hear', 'multipl', 'sourc', 'mandatori', 'quarantin', 'come', 'week', 'u', 'citizen', 'last', 'chanc', 'stock', 'food', 'amp', 'suppli', 'take', 'warn', 'late', 'coronavirusupd', 'coronavirus']\n",
      "['stock', 'drop', 'amid', 'outbreak', 'latest', 'extent', 'damag', 'share', 'price', 'sever', 'key', 'compani', 'â', 'tech', 'amp', 'mediaâ', 'â', 'auto', 'amp', 'transportationâ', 'â', 'travel', 'retail', 'amp', 'consum', 'goodsâ', 'â', 'bank', 'amp', 'financesâ', 'opportun', 'invest', 'http']\n",
      "['lot', 'u', 'go', 'self', 'isol', 'week', 'thought', 'use', 'articl', 'stay', 'sane', 'happi', 'covid', 'http']\n",
      "['panic', 'buy', 'malaysia', 'escal', 'today', 'follow', 'rumour', 'impend', 'lockdown', 'ministri', 'domest', 'trade', 'consum', 'affair', 'warn', 'peopl', 'spread', 'fake', 'news', 'farhan', 'yusoff', 'amp', 'shafwan', 'zaidon', 'panic', 'buy', 'groceri', 'http']\n",
      "['increas', 'global', 'spread', 'mass', 'begin', 'panic', 'groceri', 'store', 'becom', 'increas', 'chaotic', 'animalist', 'natur', 'surviv', 'kick', 'individu', 'start', 'hoard', 'suppli', 'http']\n",
      "['panic', 'forag', 'saffron', 'flapjack', 'nose', 'food', 'drink', 'writer', 'usual', 'say', 'includ', 'recip', 'manchestereveningnos', 'saffronflapjack', 'panicforag', 'panicforag', 'coronavirus', 'http', 'http']\n",
      "['import', 'updat', 'fan', 'regard', 'retail', 'store', 'occoquan', 'mandrilltoy', 'coronavirus', 'http']\n",
      "['pregnant', 'woman', 'make', 'sure', 'vaccin', 'date', 'wash', 'hand', 'frequent', 'stay', 'away', 'peopl', 'cough', 'amp', 'protect', 'health', 'way', 'drguptamd', 'march', 'dime', 'chief', 'medic', 'amp', 'health', 'offic', 'http']\n",
      "['free', 'deliveri', 'servic', 'fee', 'senior', 'order', 'onlin', 'gt', 'gt', 'gt', 'gt', 'gt', 'gt', 'la', 'habra', 'supermarket', 'offer', 'special', 'hour', 'shopper', 'older', 'amid', 'crisi', 'http']\n",
      "['next', 'time', 'go', 'groceri', 'store', 'purchas', 'food', 'color', 'rainbow', 'boost', 'immunesystem', 'food', 'medicin', 'immunesupport', 'fight', 'coronavirus', 'http']\n",
      "['stay', 'due', 'coronavirus', 'stock', 'fridg', 'pantri', 'stay', 'due', 'coronavirus', 'stock', 'fridg', 'pantri', 'food', 'coronavirus', 'foodshortag', 'foodsecur', 'stockpil', 'http', 'http']\n",
      "['markhoplamazian', 'letter', 'sad', 'hotel', 'respons', 'worst', 'vendor', 'associ', 'marchmad', 'fault', 'consum', 'yet', 'room', 'cost', 'night', 'will', 'offer', 'hyatt']\n",
      "['due', 'coronavirus', 'panic', 'buy', 'gone', 'new', 'level', 'usa', 'buy', 'gun', 'protect', 'franc', 'buy', 'pasta', 'ensur', 'enough', 'food', 'buy', 'toilet', 'roll', 'ensur', 'keep', 'take', 'coronavirusuk']\n",
      "['coronavirus', 'collaps', 'travel', 'stockmarket', 'econom', 'outlook', 'slip', 'govern', 'busi', 'tri', 'get', 'handl', 'http', 'retail', 'apparel', 'socialdistanc', 'store', 'closur', 'revenu']\n",
      "['ulta', 'temporarili', 'shut', 'store', 'servic', 'amid', 'coronavirus', 'fear', 'http', 'via', 'retaild', 'retail', 'brickandmortar', 'cosmet', 'pandem']\n",
      "['casualti', 'retail', 'store', 'closur', 'u', 'could', 'explod']\n",
      "['stock', 'hope', 'drop', 'everi', 'fuck', 'bog', 'roll', 'toilet', 'hope', 'food', 'bought', 'go', 'hope', 'eat', 'gone', 'food', 'get', 'sick', 'someth', 'time', 'wors', 'coronavirus', 'selfish', 'prick', 'coronapocolyps', 'shop']\n",
      "['meanwhil', 'canada', 'coupl', 'clean', 'entir', 'meat', 'section', 'store', 'http', 'via', 'youtub', 'hoard', 'coronavirus', 'nomestleft', 'nofood', 'canada', 'panic']\n",
      "['herionlin', 'fight', 'covid', 'infect', 'believ', 'social', 'distanc', 'avoid', 'contact', 'heri', 'ensur', 'worri', 'shop', 'safest', 'space', 'shall', 'deliv', 'http']\n",
      "['whole', 'store', 'ransack', 'thank', 'retail', 'worker', 'ca', 'imagin', 'crazi', 'deal', 'right', 'coronavirus', 'panicshop', 'retailwork', 'http']\n",
      "['sinc', 'kid', 'high', 'schooler', 'btw', 'groceri', 'store', 'cashier', 'appar', 'critic', 'infrastructur', 'employe', 'sudden', 'would', 'nice', 'pay', 'reflect', 'risk']\n",
      "['uk', 'consum', 'alreadi', 'make', 'small', 'signific', 'chang', 'socialis', 'shop', 'respons', 'full', 'survey', 'result', 'retailx', 'http', 'shop', 'ecommerc', 'retail', 'socialdist', 'socialdist', 'socialis', 'uk', 'http']\n",
      "['way', 'spread', 'mass', 'hysteria', 'panic', 'lead', 'peopl', 'buy', 'shelf', 'caus', 'shortag', 'nation', 'guard', 'place', 'militari', 'lockdown', 'extra', 'food', 'suppli', 'case', 'store', 'get', 'raid', 'yes']\n",
      "['find', 'need', 'work', 'food', 'deliveri', 'driver', 'seem', 'like', 'go', 'high', 'demand', 'consid', 'state', 'ban', 'din', 'coronapocolyps', 'coronavirus', 'stayhom']\n",
      "['shame', 'lead', 'stori', 'top', 'employe', 'way', 'stori', 'lead', 'heavili', 'impli', 'supermarket', 'worker', 'fact', 'corpor', 'employe', 'interact', 'store', 'general', 'public']\n",
      "['dtc', 'brand', 'look', 'toward', 'brick', 'mortar', 'store', 'way', 'facilit', 'growth', 'coronavirus', 'chang', 'http']\n",
      "['one', 'question', 'happen', 'sinc', 'manufactur', 'close', 'plant', 'covid', 'shutdown', 'mani', 'make', 'food', 'plant', 'shut', 'groceri', 'store', 'get', 'new', 'stock']\n",
      "['noth', 'beat', 'classic', 'food', 'wheel', 'get', 'big', 'mac', 'meal', 'order', 'via', 'ubereat', 'app', 'promo', 'code', 'bigmacza', 'amp', 'c', 'appli']\n",
      "['hyve', 'alway', 'thank', 'shopper', 'shop', 'hyve', 'sunday', 'march', 'blue', 'spring', 'missouri', 'howev', 'develop', 'shopper', 'begin', 'take', 'advantag', 'onlin', 'deliveri', 'form', 'obtain', 'everi', 'day', 'need', 'http']\n",
      "['asda', 'tesco', 'morrison', 'sainsburi', 'think', 'time', 'reduc', 'minimum', 'onlin', 'shop', 'basket', 'product', 'stock', 'peopl', 'need', 'think', 'forgot', 'u', 'singl', 'disabl', 'peopl', 'put', 'custom']\n",
      "['wish', 'physic', 'could', 'predict', 'much', 'sanit', 'toilet', 'paper', 'would', 'need', 'got', 'real', 'stoppanicbuy', 'coronavirus']\n",
      "['u', 'air', 'strike', 'crisi', 'iraqi', 'govern', 'may', 'find', 'deal', 'greatest', 'govern', 'challeng', 'sinc', 'isi', 'invas', 'middleeastey', 'http']\n",
      "['dcislamabad', 'sell', 'mask', 'high', 'price', 'provid', 'coronavirusinpakistan', 'coronavirusoutbreak']\n",
      "['toilet', 'paper', 'local', 'groceri', 'store', 'almost', 'week', 'real', 'crisi', 'south', 'florida', 'toiletpap', 'coronavirus', 'http']\n",
      "['coronavirus', 'go', 'shop', 'groceri', 'might', 'best', 'check', 'list', 'great', 'onlin', 'altern', 'deliv', 'right', 'door']\n",
      "['good', 'way', 'support', 'groceri', 'store', 'medic', 'hospit', 'staff', 'time', 'would', 'normal', 'think', 'someth', 'along', 'line', 'order', 'everyon', 'pizza', 'seem', 'like', 'great', 'idea', 'covid']\n",
      "['rapid', 'spread', 'leaf', 'fate', 'mani', 'announc', 'consum', 'mna', 'deal', 'jeopardi', 'public', 'market', 'fluctuat', 'consum', 'encourag', 'avoid', 'place', 'public', 'gather', 'http']\n",
      "['madam', 'baka', 'di', 'nyo', 'naranasan', 'ang', 'work', 'pay', 'isang', 'kahig', 'isang', 'tuka', 'that', 'someon', 'still', 'tri', 'go', 'work', 'realiz', 'least', 'one', 'week', 'food', 'stock', 'hope', 'leav', 'countri']\n",
      "['pleas', 'read', 'thread']\n",
      "['given', 'self', 'centr', 'amp', 'aggress', 'behaviour', 'seen', 'street', 'groceri', 'store', 'aisl', 'australia', 'thrill', 'war', 'immedi', 'threat', 'true', 'self', 'emerg', 'time', 'stress', 'amp', 'pressur', 'fail', 'previous', 'lax', 'standard', 'coronavirus']\n",
      "['well', 'im', 'actual', 'start', 'worri', 'onlin', 'food', 'shop', 'noth', 'stock', 'bread', 'pasta', 'fruit', 'veg', 'milk', 'hell', 'go', 'eat', 'far', 'chees', 'coffe', 'coronavirus', 'coronapocolyps']\n",
      "['good', 'read', 'worri', 'particip', 'groceri', 'store', 'run', 'coronavirus', 'era', 'lean', 'difficult', 'accommod', 'huge', 'discret', 'surg', 'demand', 'store', 'suppli', 'chain', 'still', 'strong', 'via', 'nytim', 'http']\n",
      "['unpreced', 'move', 'u', 'retail', 'mani', 'opt', 'indefinit', 'shut', 'door', 'prevent', 'spread', 'novel', 'coronavirus', 'other', 'like', 'walmart', 'reduc', 'hour', 'retail', 'http']\n",
      "['fl', 'agricultur', 'commission', 'fl', 'dept', 'agricultur', 'amp', 'consum', 'svcs', 'announc', 'activ', 'websit', 'famili', 'find', 'free', 'meal', 'child', 'corona', 'virus', 'closur', 'http', 'coronavirus', 'http']\n",
      "['got', 'home', 'supermarket', 'panic', 'buy', 'real', 'middl', 'afternoon', 'bet', 'queue', 'longer', 'work', 'hour', 'covid']\n",
      "['learn', 'u', 'consum', 'industri', 'includ', 'food', 'drink', 'beauti', 'retail', 'health', 'well', 'react', 'pandem', 'http', 'marketresearch', 'consumerinsight']\n",
      "['pleas', 'help', 'u', 'stock', 'food', 'coz', 'danger', 'near', 'crisi', 'covid', 'neighbour', 'countri', 'kenya', 'though', 'request', 'anyon', 'manag', 'help', 'u', 'anyth', 'small', 'coz', 'want', 'stock', 'food', 'orphanag']\n",
      "['told', 'employ', 'go', 'work', 'tonight', 'want', 'risk', 'bring', 'home', 'famili', 'work', 'retail', 'store', 'take', 'precaut', 'custom', 'come', 'area', 'confirm', 'case', 'employ', 'said', 'need', 'short']\n",
      "['french', 'presid', 'emmanuel', 'macron', 'impos', 'lockdown', 'declar', 'coronavirus', 'cancel', 'municip', 'elect', 'order', 'stay', 'home', 'allow', 'trip', 'groceri', 'store', 'pharmaci']\n",
      "['tip', 'stay', 'fraud', 'free', 'attempt', 'inform', 'feder', 'trade', 'commiss', 'visit', 'http', 'http']\n",
      "['sinc', 'religi', 'anyth', 'go', 'supermarket', 'like', 'find', 'god', 'child', 'child', 'clear', 'water', 'toilet', 'paper', 'everi', 'shelf', 'world', 'like', 'want', 'kill', 'rest', 'u', 'win', 'hunger', 'game']\n",
      "['go', 'supermarket', 'mean', 'vulner', 'crowd', 'peopl', 'trendi', 'go', 'costco', 'sam', 'club', 'place', 'go', 'multipli', 'lot', 'megachurch', 'zombi', 'shop', 'panic', 'allow', 'shop', 'care', 'die']\n",
      "['mountain', 'america', 'member', 'financi', 'impact', 'mountainamericacu', 'may', 'loan', 'relief', 'option', 'help', 'uniqu', 'situat', 'visit', 'http', 'learn', 'http']\n",
      "['mpe', 'prepar', 'continu', 'provid', 'safe', 'reliabl', 'electr', 'servic', 'adopt', 'consum', 'employe', 'safeti', 'measur', 'read', 'http', 'http']\n",
      "['bing', 'shop', 'onlin', 'quarantinelif', 'coronavirus']\n",
      "['long', 'time', 'could', 'dream', 'reid', 'distilleri', 'would', 'look', 'like', 'hard', 'overst', 'impact', 'covid', 'u', 'small', 'busi', 'best', 'way', 'support', 'enjoy', 'reid', 'gin', 'home', 'retail', 'store', 'open', 'everyday']\n",
      "['way', 'coronavirus', 'chang', 'millenni', 'money', 'habit', 'generat', 'http', 'noi', 'paghiamo', 'con', 'carta', 'credito', 'con', 'satispay', 'coronavirus', 'molti', 'acquisti', 'onlin']\n",
      "['get', 'person', 'one', 'allow', 'coronavirus', 'hysteria', 'panic', 'chang', 'home', 'life', 'went', 'groceri', 'store', 'normal', 'shop', 'beyond', 'disappoint', 'human', 'pleas', 'stop', 'think']\n",
      "['panic', 'shop', 'coronavirus', 'plan', 'end', 'food', 'water', 'toilet', 'paper', 'consum', 'also', 'panic', 'shop', 'life', 'insur', 'stayinform', 'stayconnect', 'http']\n",
      "['hello', 'brother', 'sister', 'let', 'connect', 'hand', 'support', 'child', 'stock', 'food', 'orphanag', 'main', 'afraid', 'covid', 'crisi', 'take', 'place', 'neighbour', 'countri', 'kenya', 'drc', 'congo', 'pleas', 'help']\n",
      "['social', 'distanc', 'prevent', 'spread', 'coronavirus', 'could', 'devast', 'effect', 'peopl', 'depress', 'http']\n",
      "['woolworth', 'give', 'elder', 'disabl', 'dedic', 'shop', 'hour', 'amid', 'outbreak', 'covid', 'coronavirus', 'zakat', 'http']\n",
      "['man', 'yell', 'supermarket', 'today', 'buy', 'garlic', 'soo', 'xenophob', 'either', 'realli', 'love', 'australian', 'commerc', 'think', 'covid', 'spread', 'garlic']\n",
      "['due', 'fear', 'peopl', 'start', 'hoard', 'item', 'daili', 'use', 'impact', 'regular', 'level', 'suppli', 'market', 'commod', 'disappear', 'market', 'creat', 'shortag', 'price', 'go', 'peopl', 'start', 'curs', 'govern']\n",
      "['northgat', 'market', 'allow', 'senior', 'shop', 'first', 'open', 'public', 'detail', 'gt', 'http', 'http']\n",
      "['peopl', 'die', 'peopl', 'also', 'die', 'afford', 'live', 'afford', 'food', 'child', 'let', 'alon', 'peopl', 'deserv', 'abl', 'panic', 'thought', 'nation', 'go', 'shit', 'peopl', 'deserv', 'live']\n",
      "['appar', 'everyon', 'els', 'feel', 'way', 'killer', 'bread', 'bread', 'coronavirus', 'stockup', 'davesbread', 'http', 'http']\n",
      "['korea', 'case', 'malaysia', 'case', 'yet', 'korea', 'supermarket', 'never', 'stock', 'malaysia', 'shelf', 'govern', 'total', 'consid', 'limit', 'necess', 'good', 'everi', 'consum', 'market']\n",
      "['amazon', 'say', 'coronavirus', 'outbreak', 'caus', 'surg', 'onlin', 'shop', 'onlin', 'giant', 'ad', 'new', 'posit', 'across', 'unit', 'state', 'keep', 'demand', 'report', 'cnn', 'http']\n",
      "['consum', 'respons', 'cannabisindustri', 'import', 'priorit', 'medic', 'marijuana', 'patient', 'http']\n",
      "['got', 'groceri', 'store', 'amp', 'call', 'wife', 'bread', 'want', 'grab']\n",
      "['safeti', 'measur', 'r', 'taken', 'onlin', 'shop', 'compani', 'amp', 'courier', 'partner', 'amazonin', 'flipkart', 'etc', 'fear', 'shop', 'packag', 'travel', 'vast', 'distanc', 'amp', 'r', 'handl', 'mani', 'along', 'way', 'b', 'potenti', 'coronavirus', 'carrier']\n",
      "['shop', 'hike', 'price', 'shame', 'mean', 'peopl', 'cash', 'ebay', 'etc', 'mean', 'actual', 'local', 'shop', 'increas', 'price', 'meat', 'rice', 'thought', 'tri', 'get', 'togeth', 'ridicul', 'coronavirus']\n",
      "['http', 'gaisss', 'pleas', 'read', 'pleas', 'limit', 'go', 'outsid', 'pleas', 'wash', 'hand', 'alway', 'use', 'hand', 'sanit', 'pleas', 'get', 'readi', 'stock', 'food']\n",
      "['impact', 'suppli', 'chain', 'trade', 'workforc', 'much', 'check', 'pwc', 'guid', 'busi', 'leader', 'know', 'find', 'http', 'http']\n",
      "['love', 'peopl', 'return', 'someth', 'store', 'pleas', 'let', 'wait', 'coronavirus', 'retail', 'store', 'bare', 'make', 'pleas', 'add', 'stress', 'manag', 'return', 'everyth', 'troubl', 'time']\n",
      "['track', 'effect', 'coronavirus', 'retail', 'industri', 'everi', 'step', 'way', 'read', 'first', 'blog', 'stay', 'tune', 'updat', 'everi', 'monday', 'wednesday', 'friday', 'http', 'digitalmarket']\n",
      "['consum', 'alert', 'awar', 'bogus', 'home', 'test', 'kit', 'http', 'coronavirus', 'wdbo', 'http']\n",
      "['amazon', 'say', 'need', 'hire', 'peopl', 'across', 'keep', 'crush', 'order', 'coronavirus', 'spread', 'keep', 'peopl', 'home', 'shop', 'onlin', 'http', 'via', 'abc', 'job', 'hire']\n",
      "['need', 'panic', 'buy', 'food', 'avail', 'time', 'pm', 'assur', 'http', 'http']\n",
      "['stopthespread', 'research', 'shown', 'faster', 'author', 'move', 'implement', 'kind', 'socialdistanc', 'measur', 'design', 'slow', 'transmiss', 'diseas', 'life', 'save', 'great', 'read', 'via', 'npr', 'http']\n",
      "['amaz', 'go', 'supermarket', 'everyth', 'gone', 'peopl', 'panic', 'buy', 'yet', 'one', 'singl', 'person', 'wear', 'facemask', 'buy', 'roll', 'toilet', 'paper', 'wo', 'prevent', 'catch', 'take', 'proper', 'precaut', 'stay', 'safe', 'http']\n",
      "['u', 'get', 'supermarket', 'letspan']\n",
      "['go', 'groceri', 'store', 'made', 'panic', 'anyth', 'scarciti', 'resourc', 'need', 'hoard', 'food', 'like', 'saw', 'woman', 'gallon', 'milk', 'buggi', 'egg', 'gone', 'bread', 'aisl', 'demolish', 'coronavirusoutbreak', 'coronavirus', 'coronapocolyps']\n",
      "['worth', 'read', 'hope', 'noth', 'els', 'public', 'might', 'wish', 'consid', 'shop', 'local', 'futur', 'cours', 'shop', 'like', 'u', 'surviv', 'http']\n",
      "['needl', 'say', 'caus', 'strong', 'feel', 'coronavirus', 'supermarket', 'food', 'shop', 'http']\n",
      "['san', 'francsisco', 'mayor', 'london', 'breed', 'announc', 'lockdown', 'last', 'april', 'peopl', 'allow', 'leav', 'home', 'midnight', 'tuesday', 'anyth', 'doctor', 'visit', 'groceri', 'store', 'shop', 'http', 'coronavirus']\n",
      "['pandem', 'plung', 'global', 'financi', 'market', 'drove', 'consum', 'confid', 'today', 'low', 'accord', 'morningconsult', 'survey', 'http', 'http']\n",
      "['appl', 'close', 'retail', 'locat', 'outsid', 'china', 'march', 'reopen', 'appl', 'store', 'locat', 'within', 'greater', 'china', 'http', 'appl', 'retail', 'applestor', 'coronavirus', 'health', 'close', 'quarantin', 'china', 'greaterchina']\n",
      "['need', 'panic', 'buy', 'food', 'avail', 'time', 'pm', 'assur', 'http']\n",
      "['full', 'grown', 'as', 'woman', 'counti', 'highest', 'number', 'coronavirus', 'case', 'colorado', 'groceri', 'store', 'employe', 'come', 'work', 'afford', 'take', 'time', 'store', 'even', 'reduc', 'hour', 'pleas', 'feel', 'well']\n",
      "['love', 'quiet', 'tube', 'atm', 'terribl', 'yes', 'get', 'fantast', 'level', 'consum', 'util', 'tube', 'ticket']\n",
      "['owhealth', 'time', 'turmoil', 'allow', 'format', 'deeper', 'relationship', 'insur', 'member', 'societi', 'larg', 'gt', 'http', 'coronavirus', 'http']\n",
      "['food', 'suppli', 'consum', 'welfar', 'depart', 'odisha', 'govern', 'take', 'effect', 'step', 'prevent', 'black', 'market', 'hoard', 'protect', 'mask', 'hand', 'sanit', 'state', 'odisha', 'odishanew', 'ommcomnew', 'http']\n",
      "['oregon', 'gov', 'kate', 'brown', 'monday', 'afternoon', 'order', 'oregon', 'restaur', 'bar', 'stop', 'dine', 'limit', 'sale', 'takeout', 'deliveri', 'http']\n",
      "['coronavirus', 'europ', 'call', 'calm', 'food', 'shortag', 'fear', 'spark', 'panic', 'buy', 'http']\n",
      "['even', 'amazon', 'struggl', 'deliv', 'food', 'know', 'stockpil', 'muppet', 'panic', 'buy', 'coronavirus', 'yorkshir', 'uk', 'http']\n",
      "['anthoni', 'fauci', 'said', 'peopl', 'may', 'perceiv', 'new', 'coronavirus', 'guidelin', 'inconveni', 'go', 'far', 'reflect', 'deterior', 'assess', 'contain', 'effort', 'taken', 'serious', 'http', 'http']\n",
      "['break', 'center', 'diseas', 'control', 'recommend', 'american', 'cancel', 'postpon', 'gather', 'peopl', 'next', 'eight', 'week', 'aggress', 'feder', 'guidanc', 'issu', 'yet', 'respons', 'coronavirus', 'outbreak', 'http']\n",
      "['iran', 'prison', 'releas', 'view', 'itali', 'prison', 'creat', 'nuisanc', 'amp', 'even', 'burnt', 'prison', 'cell', 'news', 'suspect', 'india', 'prison', 'make', 'face', 'mask', 'amp', 'sell', 'extrem', 'low', 'price', 'bharat']\n",
      "['updat', 'info', 'page', 'includ', 'link', 'latest', 'dhs', 'ndia', 'updat', 'plus', 'current', 'know', 'supermarket', 'rule', 'chang', 'http']\n",
      "['pymnt', 'survey', 'consum', 'alreadi', 'chang', 'daili', 'life', 'karenmpd', 'dive', 'result', 'http', 'coronavirus', 'http']\n",
      "['peopl', 'worri', 'ventil', 'worri', 'lose', 'incom', 'home', 'food', 'life', 'stop', 'bail', 'busi', 'care', 'stock', 'market', 'take', 'care', 'peopl', 'coronavirus']\n",
      "['groceri', 'store', 'employe', 'extrem', 'vulner', 'contract', 'virtu', 'expos', 'oncom', 'excess', 'panicshop', 'crowd', 'market', 'consid', 'maxim', 'station', 'reduc', 'employe', 'exposur', 'makro', 'selfquarantin', 'http']\n",
      "['consum', 'report', 'suggest', 'stock', 'day', 'import', 'medic', 'stock', 'birth', 'control', 'http']\n",
      "['consum', 'shaki', 'ground', 'busi', 'grind', 'covid', 'hear', 'consum', 'confid', 'shellykhagan', 'listen', 'http']\n",
      "['supermarket', 'absolut', 'chao', 'toilet', 'roll', 'hard', 'paracetamol', 'massiv', 'queue', 'till', 'snuff', 'result', 'go', 'come', 'back', 'haunt', 'everyon', 'stockpil']\n",
      "['quick', 'question', 'homeless', 'answer', 'also', 'go', 'usual', 'place', 'free', 'meal', 'social', 'support', 'etc', 'close', 'offer', 'limit', 'servic', 'suck', 'homeless', 'time', 'suck', 'realli', 'hard']\n",
      "['realli', 'realli', 'worri', 'mani', 'littl', 'kid', 'go', 'serious', 'hungri', 'due', 'coronavirus', 'meal', 'kid', 'get', 'school', 'could', 'serious', 'hungri', 'week', 'close', 'especi', 'also', 'stockpil', 'deni', 'food', 'bank', 'normal', 'stock']\n",
      "['covid', 'quarantinelif', 'pre', 'exist', 'medic', 'condit', 'isol', 'week', 'wife', 'work', 'supermarket', 'work']\n",
      "['supermarket', 'worker', 'homecar', 'worker', 'postal', 'worker', 'clean', 'worker', 'worker', 'throughout', 'servic', 'sector', 'find', 'forefront', 'societi', 'effort', 'contain', 'pandem', 'take', 'look', 'measur', 'need']\n",
      "['oliverscampaign', 'coronavirus', 'type', 'food', 'peopl', 'stock', 'pile', 'case', 'isol']\n",
      "['go', 'shop', 'coronavirus', 'stop', 'peopl', 'fight', 'food', 'loo', 'roll', 'stay', 'lot', 'go', 'short', 'walk', 'knit', 'shop', 'onlin']\n",
      "['shit', 'got', 'done', 'tell', 'kid', 'much', 'fun', 'gon', 'na', 'watch', 'movi', 'play', 'outsid', 'eat', 'stock', 'pile', 'food', 'next', 'see', 'talk', 'homeschool', 'curriculum', 'tho', 'coronavirus']\n",
      "['monitor', 'back', 'home', 'look', 'draconian', 'igetit', 'coronavirus', 'staythefhom', 'socialdistanc', 'selfisol', 'stopthespread', 'stoppanicbuy', 'http']\n",
      "['supermarket', 'scene', 'post', 'foreign', 'finland', 'http']\n",
      "['ron', 'price', 'go', 'diesel', 'price', 'go', 'public', 'transport', 'train', 'bus', 'teksi', 'amp', 'e', 'hail', 'servic', 'price', 'go', 'malaysia', 'year']\n",
      "['combat', 'coronavirus', 'amp', 'protect', 'staff', 'amp', 'custom', 'psucreameri', 'retail', 'store', 'close', 'notic', 'situat', 'evolv', 'rapid', 'reopen', 'date', 'uncertain', 'creameri', 'aim', 'continu', 'sell', 'via', 'wholesal', 'amp', 'onlin', 'http']\n",
      "['public', 'intervent', 'covid', 'help', 'may', 'disagre', 'govern', 'strategi', 'pleas', 'activ', 'campaign', 'govern', 'peopl', 'frighten', 'ad', 'fear', 'caus', 'panic', 'action', 'l']\n",
      "['energytwitt', 'take', 'impact', 'oil', 'price', 'collaps', 'amp', 'fall', 'energi', 'use', 'natur', 'gas', 'price', 'expect', 'product', 'price', 'drop', 'crush', 'coal', 'use', 'b', 'fall', 'product', 'price', 'rise', 'shift', 'fuel', 'power']\n",
      "['welcom', 'stophoard', 'stoppanicbuy', 'stayathom', 'staysaf', 'amid', 'coronavirus', 'coronavirusupd', 'http']\n",
      "['chief', 'medic', 'offic', 'current', 'tell', 'alan', 'jone', 'radio', 'peopl', 'buy', 'two', 'week', 'worth', 'food', 'perhap', 'need', 'tell', 'state', 'least', 'one', 'state', 'govern', 'recommend', 'exact', 'inconsist', 'gobsmack']\n",
      "['covid', 'pandem', 'self', 'isol', 'journal', 'day', 'mild', 'panic', 'set', 'paraphras', 'h', 'simpson', 'hous', 'food', 'need', 'make', 'food']\n",
      "['clothier', 'landsend', 'close', 'retail', 'store', 'march', 'due', 'coronavirus', 'pandem', 'pay', 'employe', 'time', 'period', 'store', 'hunt', 'valley', 'town', 'center', 'huntvalley', 'coronavirus', 'http']\n",
      "['trade', 'clear', 'settlement', 'tomorrow', 'march', 'notic', 'due', 'enhanc', 'communiti', 'quarantin', 'implement', 'luzon', 'http']\n",
      "['retail', 'store', 'owner', 'right', 'coronavirussa', 'http']\n",
      "['came', 'back', 'groceri', 'store', 'found', 'milk', 'egg', 'gone', 'coronavirus', 'real', 'coronapocolyps', 'coronavirusoutbreak']\n",
      "['lvmh', 'convert', 'perfum', 'factori', 'make', 'hand', 'sanit', 'retail', 'leader', 'say', 'ikea', 'ecommerc', 'strategi', 'america', 'retail', 'start', 'crowd', 'control', 'ulta', 'beauti', 'stop', 'store', 'beauti', 'servic', 'ecommerc', 'retail', 'dtc', 'coronapocalyps', 'http', 'http']\n",
      "['dad', 'holiday', 'postpon', 'need', 'quarantin', 'day', 'dubai', 'hospit', 'safeti', 'class', 'postpon', 'use', 'class', 'peopl', 'panic', 'buy', 'food', 'drink', 'supermarket', 'frustat']\n",
      "['quarantin', 'suck', 'lead', 'insur', 'amount', 'onlin', 'shop', 'coronavirus', 'shop', 'quarantinelif', 'http']\n",
      "['respons', 'novel', 'coronavirus', 'post', 'retail', 'store', 'includ', 'trelli', 'room', 'close', 'public', 'monday', 'march', 'closur', 'limit', 'hour', 'announc', 'follow', 'week', 'post', 'wine', 'avail', 'local', 'store', 'well', 'http']\n",
      "['got', 'contact', 'work', 'say', 'work', 'due', 'coronavirus', 'outbreak', 'paypal', 'beemit', 'support', 'onlin', 'shop', 'addict', 'n', 'also', 'pay', 'groceri', 'wherev', 'find', 'bc', 'shelf', 'supermarket', 'empti']\n",
      "['stockup', 'compass', 'amp', 'love', 'tissu', 'paper', 'coronaoutbreak', 'falsepan', 'coronavirus', 'worldshutdown']\n",
      "['panic', 'groceri', 'shop', 'necessari', 'put', 'peopl', 'risk', 'talk', 'sever', 'supermarket', 'employe', 'elder', 'worri', 'health', 'custom', 'crowd', 'store', 'http']\n",
      "['foodsafeti', 'tip', 'coronavirus', 'outbreak', 'includ', 'immunocompromis', 'opt', 'fruit', 'veget', 'http']\n",
      "['help', 'eat', 'well', 'limit', 'movement', 'coronavirus', 'crisi', 'download', 'applic', 'smartphon', 'make', 'easier', 'recov', 'food', 'time', 'find', 'restaur', 'groceri', 'store', 'near', 'deliv', 'healthi', 'meal', 'home']\n",
      "['wake', 'work', 'agenc', 'secur', 'access', 'allot', 'ensur', 'get', 'cattl', 'sheep', 'get', 'market', 'consum', 'plate', 'addit', 'detail', 'share', 'becom', 'avail', 'pleas', 'reach', 'question', 'concern']\n",
      "['impact', 'suppli', 'chain', 'trade', 'workforc', 'much', 'put', 'togeth', 'guid', 'busi', 'leader', 'know', 'find', 'http', 'http']\n",
      "['pharmaci', 'shop', 'sell', 'hand', 'sanit', 'ridicul', 'price', 'think', 'mother', 'sibl', 'infect', 'peopl', 'afford', 'sanit', 'high', 'price', 'know', 'smart', 'ignoranthuman', 'coronavirus', 'http']\n",
      "['pleas', 'let', 'lil', 'math', 'shall', 'peopl', 'groceri', 'store', 'one', 'time', 'mani', 'actual', 'custom', 'allow', 'due', 'number', 'worker', 'krogersupport', 'kroger', 'walmarthelp', 'woodmansfood', 'milwauke', 'coronavirus']\n",
      "['tech', 'giant', 'largest', 'groceri', 'store', 'chain', 'beij', 'fare', 'amid', 'coronavirus', 'outbreak', 'china', 'selinawangtv', 'check', 'interview', 'store', 'manag', 'coronaviruspandem', 'http']\n",
      "['mypov', 'chatter', 'background', 'full', 'u', 'lock', 'true', 'folk', 'want', 'make', 'plan', 'stock', 'food', 'water', 'thing', 'cash', 'etc', 'prepper', 'alreadi', 'could', 'last', 'wks', 'peak', 'transmiss', 'coronavirus']\n",
      "['homebound', 'due', 'work', 'cramp', 'condit', 'set', 'home', 'workstat', 'room', 'coronavirus', 'consum', 'report', 'http']\n",
      "['guy', 'take', 'whole', 'coronavirus', 'stride', 'sensibl', 'panick', 'general', 'enjoy', 'stoppanicbuy', 'staysaf', 'mainecoon', 'http']\n",
      "['today', 'went', 'supermarket', 'buy', 'groat', 'pasta', 'remain', 'shelf']\n",
      "['blrcitypolic', 'pleas', 'could', 'let', 'know', 'address', 'issu', 'regist', 'clinic', 'mask', 'inflat', 'price', 'cash', 'current', 'crisi', 'bengaluru']\n",
      "['plenti', 'food', 'american', 'alarm', 'empti', 'groceri', 'shelf', 'food', 'supplier', 'amp', 'retail', 'say', 'struggl', 'surg', 'demand', 'insist', 'suppli', 'chain', 'remain', 'strong', 'panicbuy', 'coronavirus', 'http']\n",
      "['shopper', 'bulk', 'buy', 'need', 'panic', 'stock', 'excess', 'enough', 'food', 'suppli', 'per', 'ministri', 'import', 'rememb', 'keep', 'older', 'adult', 'thought', 'bulk', 'buy', 'coronavirus', 'http']\n",
      "['texa', 'health', 'resourc', 'coronavirus', 'consum', 'hotlin', 'spoken', 'regist', 'nurs', 'morn', 'abl', 'answer', 'question', 'great', 'resourc']\n",
      "['prevent', 'better', 'cure', 'let', 'beat', 'coronavirus', 'wash', 'hand', 'frequent', 'soap', 'wear', 'mask', 'use', 'clean', 'cloth', 'cover', 'mouth', 'crowd', 'place', 'tri', 'make', 'one', 'meter', 'distanc', 'stranger', 'eat', 'homemad', 'food', 'much', 'possibl', 'let', 'panic', 'http']\n",
      "['supermarket', 'chain', 'kroger', 'said', 'two', 'employe', 'test', 'posit', 'virus', 'recov', 'one', 'employ', 'king', 'sooper', 'groceri', 'chain', 'colorado', 'fred', 'meyer', 'groceri', 'chain', 'washington', 'state']\n",
      "['jack', 'cdcgov', 'big', 'box', 'retail', 'go', 'le', 'mani', 'store', 'employe', 'alon', 'custom', 'enter', 'coronavirus', 'retail']\n",
      "['blakkrasta', 'pls', 'tell', 'pharmacist', 'drop', 'price', 'sanit', 'cruel', 'africanhistoryclass', 'taxidrivershow', 'taxijam', 'blackpot', 'gumahdok', 'rastakwadzo', 'eugenpeprah']\n",
      "['id', 'much', 'onlin', 'shop', 'right', 'compani', 'start', 'run', 'coronavirus', 'sale', 'like', 'whole', 'websit', 'type', 'sale', 'lol']\n",
      "['teetrumpett', 'gayrepublicswag', 'will', 'ignor', 'amp', 'deliber', 'blind', 'medium', 'far', 'accur', 'king', 'lie', 'market', 'react']\n",
      "['onlin', 'shop', 'way', 'stuff', 'http']\n",
      "['despit', 'effort', 'affect', 'coronavirus', 'oil', 'market', 'go', 'short', 'sharp', 'shock', 'startof', 'prolong', 'period', 'lower', 'price', 'refinitiv', 'ehsan', 'talk', 'roger', 'hirst', 'http', 'datanow', 'trusteddata']\n",
      "['know', 'like', 'lot', 'kind', 'freak', 'nervous', 'rememb', 'protect', 'u', 'kind', 'extrem', 'measur', 'work', 'told', 'stick', 'figur', 'sound', 'effect', 'voic', 'http']\n",
      "['question', 'remain', 'impact', 'coronavirus', 'communiti', 'mean', 'consum', 'spend', 'pattern', 'corpor', 'confid', 'region', 'asset', 'manag', 'perspect', 'market', 'react', 'week', 'http']\n",
      "['adobeexpcloud', 'onlin', 'shop', 'behavior', 'surg', 'last', 'week', 'trend', 'takeaway', 'top', 'u', 'retail', 'http']\n",
      "['u', 'consum', 'industri', 'includ', 'food', 'drink', 'beauti', 'retail', 'health', 'well', 'react', 'pandem', 'http', 'via', 'mintelnew']\n",
      "['roguesnradvisor', 'demand', 'rep', 'defund', 'border', 'wall', 'amp', 'put', 'fight', 'coronavirus', 'need', 'money', 'sick', 'leav', 'food', 'student', 'loan', 'mortgag', 'expens', 'test', 'treatment', 'etc', 'sick', 'peopl', 'sta']\n",
      "['coronavirus', 'place', 'u', 'war', 'foot', 'follow', 'money', 'bond', 'amp', 'stock', 'crash', 'bother', 'hand', 'wash', 'food', 'run', 'amp', 'money', 'run', 'dri', 'demand', 'suppli', 'fuck', 'loot', 'amp', 'shoot', 'http']\n",
      "['econom', 'perspect', 'global', 'inflat', 'perspect', 'march', 'u', 'consumpt', 'fold', 'grow', 'uncertainti', 'around', 'trigger', 'panic', 'buy', 'govern', 'toilet', 'paper', 'alik', 'consum', 'confid', 'survey', 'soon', 'reflectâ', 'http', 'http']\n",
      "['walmart', 'cut', 'store', 'hour', 'restock', 'retail', 'giant', 'reduc', 'store', 'oper', 'hour', 'give', 'employe', 'time', 'restock', 'shelf', 'clean', 'sanit', 'store', 'http', 'retail', 'restock', 'store', 'coronavirus', 'walmart', 'retailtrend']\n",
      "['h', 'amp', 'sale', 'hit', 'billion', 'coronavirus', 'prompt', 'store', 'closur', 'http']\n",
      "['boltgrrl', 'teetrumpett', 'gayrepublicswag', 'suppli', 'line', 'refer', 'b', 'market', 'react', 'downturn', 'consum', 'activ', 'disput', 'caus', 'dow']\n",
      "['thought', 'one', 'stock', 'pile', 'toilet', 'roll', 'could', 'hygien', 'one', 'cough', 'tissu', 'hand', 'one', 'store', 'food', 'could', 'buy', 'nan', 'young', 'child', 'coronavirus']\n",
      "['look', 'bright', 'spot', 'studi', 'show', 'babi', 'spare', 'sever', 'symptom', 'http']\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-171-f3a2b52b0a4b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_processed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOriginalTweet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtest_processed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOriginalTweet\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-170-524c9fb56d4e>\u001b[0m in \u001b[0;36mpreprocess\u001b[1;34m(docs)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdocs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mtokenized\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         cleaned = [stemmer.stem(lemmatizer.lemmatize(token.lower()))\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtokenized\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtoken\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"english\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-170-524c9fb56d4e>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      8\u001b[0m         cleaned = [stemmer.stem(lemmatizer.lemmatize(token.lower()))\n\u001b[0;32m      9\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtokenized\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtoken\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"english\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         if token.isalpha()]\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\nltk\\corpus\\reader\\wordlist.py\u001b[0m in \u001b[0;36mwords\u001b[1;34m(self, fileids, ignore_lines_startswith)\u001b[0m\n\u001b[0;32m     23\u001b[0m         return [\n\u001b[0;32m     24\u001b[0m             \u001b[0mline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mline_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mignore_lines_startswith\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         ]\n",
      "\u001b[1;32m~\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\nltk\\corpus\\reader\\wordlist.py\u001b[0m in \u001b[0;36mraw\u001b[1;34m(self, fileids)\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m             \u001b[0mfileids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfileids\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfileids\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\nltk\\corpus\\reader\\wordlist.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m             \u001b[0mfileids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfileids\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfileids\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\nltk\\corpus\\reader\\api.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, file)\u001b[0m\n\u001b[0;32m    211\u001b[0m         \"\"\"\n\u001b[0;32m    212\u001b[0m         \u001b[0mencoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 213\u001b[1;33m         \u001b[0mstream\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_root\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    214\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, encoding)\u001b[0m\n\u001b[0;32m    345\u001b[0m         \u001b[0mstream\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    346\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mencoding\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 347\u001b[1;33m             \u001b[0mstream\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSeekableUnicodeStreamReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    348\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\nltk\\compat.py\u001b[0m in \u001b[0;36m_decorator\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    226\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_decorator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m         \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_py3_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 228\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0minit_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    229\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_decorator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, stream, encoding, errors)\u001b[0m\n\u001b[0;32m   1155\u001b[0m            beginning of ``linebuffer`` (which is required by ``tell()``).\"\"\"\n\u001b[0;32m   1156\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1157\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_bom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_bom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1158\u001b[0m         \"\"\"The length of the byte order marker at the beginning of\n\u001b[0;32m   1159\u001b[0m            the stream (or None for no byte order marker).\"\"\"\n",
      "\u001b[1;32m~\\anaconda3\\envs\\machinelearning\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36m_check_bom\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1522\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbom_info\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1523\u001b[0m             \u001b[1;31m# Read a prefix, to check against the BOM(s)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1524\u001b[1;33m             \u001b[0mbytes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1525\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1526\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_processed = preprocess(train.OriginalTweet)\n",
    "test_processed = preprocess(test.OriginalTweet)"
   ]
  },
  {
   "source": [
    "## Setting Train and Test sets\n",
    "Before anything, I would just like to check the sizes of the processed data to be used."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train preprocessed: 41157\nTest preprocessed: 3798\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train preprocessed: {len(train_processed)}\")\n",
    "print(f\"Test preprocessed: {len(test_processed)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "41157\n3798\n"
     ]
    }
   ],
   "source": [
    "print(len(train.Sentiment))\n",
    "print(len(test.Sentiment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data\n",
    "X_train = train_processed\n",
    "y_train = train.Sentiment\n",
    "# test data\n",
    "X_test = test_processed\n",
    "y_test = test.Sentiment"
   ]
  },
  {
   "source": [
    "## Pipeline with *Count Vectorizer*, *TF-IDF Transformer*, and *Logistic Regression*"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.5s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   4.3s\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
       "                ('clf', LogisticRegression(n_jobs=-1))],\n",
       "         verbose=1)"
      ]
     },
     "metadata": {},
     "execution_count": 116
    }
   ],
   "source": [
    "model = Pipeline(\n",
    "    [\n",
    "     ('vect', CountVectorizer()),\n",
    "     ('tfidf', TfidfTransformer()),\n",
    "     ('clf', LogisticRegression(n_jobs=-1))\n",
    "    ], verbose=1)\n",
    "\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.5626645602948921"
      ]
     },
     "metadata": {},
     "execution_count": 120
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                    precision    recall  f1-score   support\n\nExtremely Negative       0.63      0.47      0.54       592\nExtremely Positive       0.68      0.57      0.62       599\n          Negative       0.52      0.53      0.53      1041\n           Neutral       0.61      0.66      0.63       619\n          Positive       0.50      0.59      0.54       947\n\n          accuracy                           0.56      3798\n         macro avg       0.59      0.56      0.57      3798\n      weighted avg       0.57      0.56      0.56      3798\n\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_test)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "source": [
    "## Using CV"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.5771650252839542"
      ]
     },
     "metadata": {},
     "execution_count": 112
    }
   ],
   "source": [
    "scores = cross_val_score(model, X_train, y_train, cv=10, scoring='f1_macro')\n",
    "scores.mean()"
   ]
  },
  {
   "source": [
    "Initially, with the basic preprocessing above, the model performs poorly. This is due to not having tags for potential retweets, mentions, hashtags, and possibly some emojis down the line. So, to correct those presumption of errors, I will be preprocessing the tweets in that manner. And looking at the current state of the X_train proves that."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['menyrbi chrisitv http http http',\n",
       " 'advic talk neighbour famili exchang phone number creat contact list phone number neighbour school employ chemist gp set onlin shop account po adequ suppli regular med order',\n",
       " 'coronavirus australia woolworth give elder disabl dedic shop hour amid outbreak http',\n",
       " 'food stock one empti pleas panic enough food everyon take need stay calm stay safe coronavirus confin confinementot confinementgener http',\n",
       " 'readi go supermarket outbreak paranoid food stock litterali empti coronavirus serious thing pleas panic caus shortag coronavirusfr restezchezv stayathom confin http',\n",
       " 'news first confirm case came sullivan counti last week peopl flock area store purchas clean suppli hand sanit food toilet paper good report http',\n",
       " 'cashier groceri store share insight prove credibl comment civic class know talk http',\n",
       " 'supermarket today buy toilet paper rebel toiletpapercrisi http',\n",
       " 'due retail store classroom atlanta open busi class next two week begin monday march continu process onlin phone order normal thank understand http']"
      ]
     },
     "metadata": {},
     "execution_count": 150
    }
   ],
   "source": [
    "X_train[0:9]"
   ]
  },
  {
   "source": [
    "The mentions and hyperlinks are still there. For the hashtags, I would want to preserve them as much as possible since some of the tweets do have hashtags that relate to COVID-19."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## A Twitter-focused Preprocessor"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['@',\n",
       " 'MeNyrbie',\n",
       " '@',\n",
       " 'Phil_Gahan',\n",
       " '@',\n",
       " 'Chrisitv',\n",
       " 'https',\n",
       " ':',\n",
       " '//t.co/iFz9FAn2Pa',\n",
       " 'and',\n",
       " 'https',\n",
       " ':',\n",
       " '//t.co/xX6ghGFzCC',\n",
       " 'and',\n",
       " 'https',\n",
       " ':',\n",
       " '//t.co/I2NlzdxNo8']"
      ]
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "word_tokenize(train.OriginalTweet[0])"
   ]
  },
  {
   "source": [
    "*word_tokenize* does not work well with tweets, so I have to make my own preprocessor with some regex."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoticons_str = r\"\"\"\n",
    "    (?:\n",
    "        [:=;] # Eyes\n",
    "        [oO\\-]? # Nose (optional)\n",
    "        [D\\)\\]\\(\\]/\\\\OpP] # Mouth\n",
    "    )\"\"\"\n",
    " \n",
    "regex_str = [\n",
    "    emoticons_str,\n",
    "    r'<[^>]+>', # HTML tags\n",
    "    r'(?:@[\\w_]+)', # mentions\n",
    "    r\"(?:\\#+[\\w_]+[\\w\\'_\\-]*[\\w_]+)\", # hashtags\n",
    "    r'http[s]?://(?:[a-z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+', # URLs\n",
    " \n",
    "    r'(?:(?:\\d+,?)+(?:\\.?\\d+)?)', # numbers\n",
    "    r\"(?:[a-z][a-z'\\-_]+[a-z])\", # words with - and '\n",
    "    r'(?:[\\w_]+)', # other words\n",
    "    r'(?:\\S)' # anything else\n",
    "]\n",
    "    \n",
    "emoticon_re = re.compile(r'^'+emoticons_str+'$', re.VERBOSE | re.IGNORECASE)\n",
    "tokens_re = re.compile(r'('+'|'.join(regex_str)+')', re.VERBOSE | re.IGNORECASE)\n",
    " \n",
    "def tokenize(s):\n",
    "    return tokens_re.findall(s)\n",
    " \n",
    "def preprocess_v2(s, lowercase=False):\n",
    "    preprocessed = []\n",
    "    for doc in s:\n",
    "        tokens = tokenize(doc)\n",
    "\n",
    "        if lowercase:\n",
    "            tokens = [token if emoticon_re.search(token) else token.lower() for token in tokens]\n",
    "\n",
    "        untokenized = \" \".join(tokens)\n",
    "        filtered = ' '.join(re.sub(\"(@[A-Za-z0-9_]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\",\" \",untokenized).split())\n",
    "        preprocessed.append(filtered)\n",
    "        \n",
    "    return preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_X_train = preprocess_v2(train.OriginalTweet)\n",
    "n_X_test = preprocess_v2(test.OriginalTweet)"
   ]
  },
  {
   "source": [
    "## Rerunnning Pipeline Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   6.1s\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.5703001579778831"
      ]
     },
     "metadata": {},
     "execution_count": 55
    }
   ],
   "source": [
    "model.fit(n_X_train, y_train)\n",
    "model.score(n_X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "                    precision    recall  f1-score   support\n\nExtremely Negative       0.64      0.46      0.53       592\nExtremely Positive       0.67      0.51      0.58       599\n          Negative       0.53      0.56      0.54      1041\n           Neutral       0.65      0.68      0.66       619\n          Positive       0.50      0.63      0.56       947\n\n          accuracy                           0.57      3798\n         macro avg       0.60      0.56      0.57      3798\n      weighted avg       0.58      0.57      0.57      3798\n\n"
     ]
    }
   ],
   "source": [
    "n_pred = model.predict(n_X_test)\n",
    "print(classification_report(y_test, n_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.7s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   5.3s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.7s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   5.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.7s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   5.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.7s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   5.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.7s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   5.0s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.7s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   5.2s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.7s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   5.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.7s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   5.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.7s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   5.1s\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=   0.7s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   0.0s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   5.1s\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.574792015727683"
      ]
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "source": [
    "n_scores = cross_val_score(model, n_X_train, y_train, cv=10, scoring='f1_macro')\n",
    "n_scores.mean()"
   ]
  },
  {
   "source": [
    "While the filtered model gave a better score, the difference is not significant enough to say that this project should end here. I am definitely banking on tuning the models algorithms more over the week. For now, the filtered data works better as a starting point."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}